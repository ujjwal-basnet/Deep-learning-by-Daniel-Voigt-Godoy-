{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, \\\n",
    "precision_recall_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "sys.path.append(parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fundamentas.stepbystep_v0 import StepByStep "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data generation \n",
    "X , y = make_moons(n_samples= 100 , noise = 0.3 , random_state= 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train test split\n",
    "X_train , X_val , y_train , y_val = train_test_split(X , y ,test_size=0.2 , random_state= 13)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standaerrize the feature using scikit learn standard scale \n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train = sc.transform(X_train)\n",
    "X_val = sc.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 2)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data PreParation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "X_train_tensor = torch.as_tensor(X_train).float()\n",
    "y_train_tensor = torch.as_tensor(y_train).view(-1,1).float()\n",
    "\n",
    "X_val_tensor = torch.as_tensor(X_val).float()\n",
    "y_val_tensor = torch.as_tensor(y_val).view(-1 , 1).float()\n",
    "\n",
    "#make data set \n",
    "train_dataset = TensorDataset(X_train_tensor , y_train_tensor)\n",
    "test_dataset = TensorDataset(X_val_tensor , y_val_tensor)\n",
    "\n",
    "#build data loader \n",
    "train_loader = DataLoader(\n",
    "    dataset= train_dataset , \n",
    "    shuffle= True , \n",
    "    batch_size= 16 )\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset= test_dataset , \n",
    "    batch_size = 16\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two countries  , Country A  , Countrty B \n",
    "Country A has 75 percent of wining \n",
    "Country B has 100 - 75 -> 25% wining change\n",
    "\n",
    "Wining odds are [probability]\n",
    "3 to 1 (75 / 25)\n",
    "and 1 to 3 (25 / 75) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.0, 0.3333333333333333)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ods_ratio(prob):\n",
    "    return prob/(1-prob)\n",
    "\n",
    "p = .75 \n",
    "q = 1-p\n",
    "ods_ratio(p) , ods_ratio(q) \n",
    "#note that these are the probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# map probability in real number "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0986122886681098, -1.0986122886681098)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#by taking log of odds ratio , the funciton make its symemetrical and also maps probabilities into real numbers \n",
    "def log_odds_ratio(prob):\n",
    "    return np.log(ods_ratio(prob))\n",
    "\n",
    "p = .75\n",
    "q = 1 - p \n",
    "\n",
    "log_odds_ratio(p) , log_odds_ratio(q)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.75, 0.25)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sigmoid \n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "p = .75\n",
    "q = 1-p\n",
    "sigmoid(log_odds_ratio(p)) , sigmoid(log_odds_ratio(q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('linear.weight', tensor([[0.5406, 0.5869]])),\n",
       "             ('linear.bias', tensor([-0.1657]))])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sequential model to build own logistic regression in pytorch\n",
    "torch.manual_seed(42)\n",
    "model1 = nn.Sequential()\n",
    "model1.add_module('linear' , nn.Linear(2 ,1))\n",
    "model1.add_module('sigmoid' , nn.Sigmoid()) \n",
    "model1.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### let assume two dummy data points  \n",
    "#### assume our model make prediction for them 0.9 and 0.2 \n",
    "##### i.e 90 percent probability for being positive and 20% of being positive for actual negative "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1643)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_lables = torch.tensor([1.0 , 0.0])\n",
    "dummy_predictions = torch.tensor([0.9 , .2])\n",
    "\n",
    "# positve class (lables = 1 )\n",
    "positive_pred = dummy_predictions[dummy_lables== 1 ]\n",
    "first_sumation = torch.log(positive_pred).sum()\n",
    "\n",
    "negative_pred = dummy_predictions[dummy_lables == 0]\n",
    "second_sumation = torch.log( 1 - negative_pred).sum()\n",
    "\n",
    "# n total \n",
    "n_total = dummy_lables.size(0)\n",
    "loss  = -(first_sumation + second_sumation) / n_total\n",
    "loss \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first sum add's error corresponding to positive class ,\n",
    " second sums add's erros corresponing to negative class "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BCELOSS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nn.BCELoss() is a higher function takes two argument \n",
    "1) reduction mean , sum, none \n",
    "2) weight , default is none "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\software\\miniconda\\envs\\mlenv\\Lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BCELoss()"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn = nn.BCELoss(reduce= 'mean')\n",
    "loss_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## important  , always pass prediction first and then laels  , the order matters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1643), tensor(15.0000))"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rightway_loss = loss_fn(dummy_predictions , dummy_lables)\n",
    "wrongway_loss = loss_fn(dummy_lables , dummy_predictions)\n",
    "rightway_loss , wrongway_loss "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Another Binary Cross Entropy\n",
    "### BCEWITHLOGITS \n",
    "### nn.BECWITHLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.BEc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
