{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import torch \n",
    "import torch.optim as optim \n",
    "import torch.nn as nn \n",
    "import torch.functional as F\n",
    "from  torch.utils.data import DataLoader , TensorDataset  \n",
    "from sklearn.datasets import make_moons \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import confusion_matrix, roc_curve , precision_recall_curve , auc \n",
    "import os \n",
    "import sys "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i generate_dataset.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "image , lables = generate_dataset(img_size= 5 , \n",
    "                                  n_images = 300 , \n",
    "                                  binary = True , \n",
    "                                  seed = 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([300, 1, 5, 5]), torch.Size([300, 1]))"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data preparaation \n",
    "x_tensor = torch.as_tensor(image/255)\n",
    "y_tensor = torch.as_tensor(lables.reshape(-1 , 1)).float()\n",
    "x_tensor.shape , y_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data transformation \n",
    "from torch.utils.data import Dataset \n",
    "class TransformaTensorDataset(Dataset):\n",
    "    def __init__(self , x ,y , transform = None ):\n",
    "        self.x = x \n",
    "        self.y = y \n",
    "        self.transform  = transform \n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x_item = self.x[index]\n",
    "        y_item = self.y[index]\n",
    "\n",
    "        if self.transform:\n",
    "            x_item = self.transform(x_item)\n",
    "\n",
    "        return x_item , y_item\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets , transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "composer = transforms.Compose([transforms.RandomHorizontalFlip(p = 0.5 ) ,\n",
    "                               transforms.Normalize(mean=(.5) , std = (.5))])\n",
    "datasets = TransformaTensorDataset(x_tensor , y_tensor , composer )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "#index splitter \n",
    "def index_splitter(n , splits , seed = 13):\n",
    "    idx = torch.arange(n)\n",
    "    splits = torch.as_tensor(splits)\n",
    "    multiplyer = n / splits.sum()\n",
    "     \n",
    "    splits = (multiplyer * splits).long()\n",
    "    diff = n - splits.sum() \n",
    "    splits[0] = splits[0]   + diff \n",
    "\n",
    "    torch.manual_seed(42)\n",
    "    return random_split(idx , splits)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx , val_idx = index_splitter(len(x_tensor ) , [80 , 20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[42,\n",
       " 61,\n",
       " 286,\n",
       " 160,\n",
       " 30,\n",
       " 265,\n",
       " 172,\n",
       " 205,\n",
       " 218,\n",
       " 86,\n",
       " 38,\n",
       " 50,\n",
       " 182,\n",
       " 94,\n",
       " 49,\n",
       " 22,\n",
       " 23,\n",
       " 71,\n",
       " 237,\n",
       " 208,\n",
       " 14,\n",
       " 65,\n",
       " 63,\n",
       " 149,\n",
       " 263,\n",
       " 113,\n",
       " 295,\n",
       " 273,\n",
       " 187,\n",
       " 56,\n",
       " 0,\n",
       " 250,\n",
       " 127,\n",
       " 274,\n",
       " 151,\n",
       " 209,\n",
       " 24,\n",
       " 10,\n",
       " 230,\n",
       " 276,\n",
       " 106,\n",
       " 231,\n",
       " 211,\n",
       " 201,\n",
       " 36,\n",
       " 53,\n",
       " 223,\n",
       " 155,\n",
       " 165,\n",
       " 17,\n",
       " 120,\n",
       " 216,\n",
       " 238,\n",
       " 148,\n",
       " 3,\n",
       " 13,\n",
       " 259,\n",
       " 152,\n",
       " 6,\n",
       " 110,\n",
       " 206,\n",
       " 128,\n",
       " 40,\n",
       " 247,\n",
       " 270,\n",
       " 166,\n",
       " 171,\n",
       " 194,\n",
       " 103,\n",
       " 181,\n",
       " 267,\n",
       " 1,\n",
       " 76,\n",
       " 196,\n",
       " 134,\n",
       " 284,\n",
       " 191,\n",
       " 256,\n",
       " 80,\n",
       " 102,\n",
       " 294,\n",
       " 157,\n",
       " 176,\n",
       " 156,\n",
       " 62,\n",
       " 5,\n",
       " 72,\n",
       " 285,\n",
       " 91,\n",
       " 163,\n",
       " 277,\n",
       " 28,\n",
       " 87,\n",
       " 261,\n",
       " 137,\n",
       " 150,\n",
       " 229,\n",
       " 121,\n",
       " 129,\n",
       " 161,\n",
       " 170,\n",
       " 275,\n",
       " 219,\n",
       " 212,\n",
       " 249,\n",
       " 39,\n",
       " 239,\n",
       " 235,\n",
       " 97,\n",
       " 131,\n",
       " 115,\n",
       " 174,\n",
       " 107,\n",
       " 52,\n",
       " 266,\n",
       " 33,\n",
       " 116,\n",
       " 81,\n",
       " 251,\n",
       " 138,\n",
       " 179,\n",
       " 45,\n",
       " 101,\n",
       " 60,\n",
       " 19,\n",
       " 204,\n",
       " 48,\n",
       " 297,\n",
       " 243,\n",
       " 12,\n",
       " 18,\n",
       " 67,\n",
       " 68,\n",
       " 44,\n",
       " 260,\n",
       " 268,\n",
       " 74,\n",
       " 192,\n",
       " 55,\n",
       " 57,\n",
       " 29,\n",
       " 70,\n",
       " 207,\n",
       " 9,\n",
       " 175,\n",
       " 142,\n",
       " 125,\n",
       " 245,\n",
       " 180,\n",
       " 117,\n",
       " 58,\n",
       " 167,\n",
       " 146,\n",
       " 193,\n",
       " 242,\n",
       " 287,\n",
       " 258,\n",
       " 292,\n",
       " 190,\n",
       " 26,\n",
       " 123,\n",
       " 221,\n",
       " 199,\n",
       " 215,\n",
       " 126,\n",
       " 173,\n",
       " 291,\n",
       " 188,\n",
       " 111,\n",
       " 178,\n",
       " 92,\n",
       " 296,\n",
       " 64,\n",
       " 144,\n",
       " 213,\n",
       " 75,\n",
       " 262,\n",
       " 108,\n",
       " 184,\n",
       " 203,\n",
       " 248,\n",
       " 233,\n",
       " 104,\n",
       " 73,\n",
       " 252,\n",
       " 51,\n",
       " 269,\n",
       " 299,\n",
       " 114,\n",
       " 122,\n",
       " 272,\n",
       " 59,\n",
       " 105,\n",
       " 195,\n",
       " 220,\n",
       " 228,\n",
       " 197,\n",
       " 37,\n",
       " 143,\n",
       " 162,\n",
       " 226,\n",
       " 227,\n",
       " 290,\n",
       " 8,\n",
       " 255,\n",
       " 232,\n",
       " 118,\n",
       " 31,\n",
       " 225,\n",
       " 130,\n",
       " 264,\n",
       " 280,\n",
       " 224,\n",
       " 271,\n",
       " 236,\n",
       " 147,\n",
       " 189,\n",
       " 32,\n",
       " 293,\n",
       " 185,\n",
       " 278,\n",
       " 85,\n",
       " 100,\n",
       " 88,\n",
       " 11,\n",
       " 119,\n",
       " 34,\n",
       " 47,\n",
       " 214,\n",
       " 153,\n",
       " 79,\n",
       " 135,\n",
       " 140,\n",
       " 168,\n",
       " 133,\n",
       " 240,\n",
       " 99,\n",
       " 288,\n",
       " 136,\n",
       " 217]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_idx.indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "val_sampler = SubsetRandomSampler(val_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build a loader of each sets \n",
    "\n",
    "train_loader = DataLoader(dataset= datasets  , \n",
    "                          batch_size = 16 , sampler = train_sampler )\n",
    "\n",
    "val_loader = DataLoader(dataset = datasets , batch_size = 16 , sampler = val_sampler)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " #check if loaders are returning corect number of mini -batches \n",
    "len(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(iter(val_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data augumentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tensor  =  x_tensor[train_idx]\n",
    "x_val_tensor  =  x_tensor[val_idx]\n",
    "y_train_tensor  =  y_tensor[train_idx]\n",
    "y_val_tensor  =  y_tensor[val_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "#composer \n",
    "train_composer = transforms.Compose([transforms.RandomHorizontalFlip(p = .5), \n",
    "                                                                     transforms.Normalize(mean = (.5) , std = (.5))])\n",
    "\n",
    "val_composer = transforms.Compose([transforms.RandomHorizontalFlip(p = .5) , transforms.Normalize(mean = (.5) , std = (.5))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create their corresponding data loader\n",
    "\n",
    "train_dataset = TransformaTensorDataset( x_train_tensor , y_train_tensor , transform = train_composer     \n",
    ")\n",
    "\n",
    "val_dataset = TransformaTensorDataset(x_val_tensor , y_val_tensor , transform= val_composer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "#builds a loader of each set \n",
    "\n",
    "train_loader =  DataLoader(\n",
    "    dataset  = train_dataset , batch_size = 16 , shuffle= True \n",
    ")\n",
    "val_loader = DataLoader(dataset= val_dataset , batch_size = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import WeightedRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes , counts = y_train_tensor.unique(return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0119, 0.0064])"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.0 / counts.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = 1.0 / counts.float()\n",
    "sample_weights = weights[y_train_tensor.squeeze().long()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = torch.Generator()\n",
    "sampler = WeightedRandomSampler(\n",
    "  weights=sample_weights,\n",
    "  num_samples=len(sample_weights),\n",
    "  generator=generator,\n",
    "  replacement=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "#again \n",
    "train_loader = DataLoader(\n",
    "    dataset= train_dataset , batch_size = 16 , sampler = sampler \n",
    ")\n",
    "val_loader = DataLoader(dataset= val_dataset , batch_size= 16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = make_balanced_sampler(y_train_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_balanced_sampler(y):\n",
    "    classes ,counts = y.unique(return_counts = True)\n",
    "    weights = 1.0 /counts.float()\n",
    "    sample_weights  = weights[y.squeeze().long()]\n",
    "    #build sampler with compute weights\n",
    "    \n",
    "    generator = torch.Generator()\n",
    "    sampler = WeightedRandomSampler(\n",
    "        weights = sample_weights , \n",
    "        num_samples= len(sample_weights), \n",
    "        generator = generator ,  \n",
    "        replacement = True \n",
    "    )\n",
    "    return sampler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(9.),\n",
       " tensor(8.),\n",
       " tensor(9.),\n",
       " tensor(6.),\n",
       " tensor(5.),\n",
       " tensor(7.),\n",
       " tensor(7.),\n",
       " tensor(10.),\n",
       " tensor(8.),\n",
       " tensor(3.),\n",
       " tensor(6.),\n",
       " tensor(5.),\n",
       " tensor(9.),\n",
       " tensor(9.),\n",
       " tensor(7.)]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "([t[1].sum() for t in iter(train_loader)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(self , seed = 42):\n",
    "    torch.backends.cudnn.deterministic = True \n",
    "    torch.backends.cudnn.benchmark = False \n",
    "    torch.manual_seed(seed)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(241)\n",
      "tensor(41)\n",
      "tensor(222)\n",
      "tensor(186)\n",
      "tensor(282)\n",
      "tensor(4)\n",
      "tensor(77)\n",
      "tensor(82)\n",
      "tensor(158)\n",
      "tensor(159)\n",
      "tensor(234)\n",
      "tensor(145)\n",
      "tensor(69)\n",
      "tensor(283)\n",
      "tensor(95)\n",
      "tensor(27)\n",
      "tensor(244)\n",
      "tensor(21)\n",
      "tensor(93)\n",
      "tensor(164)\n",
      "tensor(25)\n",
      "tensor(246)\n",
      "tensor(66)\n",
      "tensor(112)\n",
      "tensor(2)\n",
      "tensor(124)\n",
      "tensor(279)\n",
      "tensor(83)\n",
      "tensor(141)\n",
      "tensor(54)\n",
      "tensor(43)\n",
      "tensor(139)\n",
      "tensor(200)\n",
      "tensor(177)\n",
      "tensor(16)\n",
      "tensor(89)\n",
      "tensor(198)\n",
      "tensor(254)\n",
      "tensor(35)\n",
      "tensor(183)\n",
      "tensor(90)\n",
      "tensor(298)\n",
      "tensor(169)\n",
      "tensor(257)\n",
      "tensor(154)\n",
      "tensor(84)\n",
      "tensor(109)\n",
      "tensor(132)\n",
      "tensor(15)\n",
      "tensor(253)\n",
      "tensor(202)\n",
      "tensor(281)\n",
      "tensor(96)\n",
      "tensor(289)\n",
      "tensor(46)\n",
      "tensor(98)\n",
      "tensor(7)\n",
      "tensor(78)\n",
      "tensor(20)\n",
      "tensor(210)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 0 \n",
    "for i in val_idx:\n",
    "    print(i)\n",
    "    a = a + 1\n",
    "\n",
    "a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(42)\n",
      "tensor(61)\n",
      "tensor(286)\n",
      "tensor(160)\n",
      "tensor(30)\n",
      "tensor(265)\n",
      "tensor(172)\n",
      "tensor(205)\n",
      "tensor(218)\n",
      "tensor(86)\n",
      "tensor(38)\n",
      "tensor(50)\n",
      "tensor(182)\n",
      "tensor(94)\n",
      "tensor(49)\n",
      "tensor(22)\n",
      "tensor(23)\n",
      "tensor(71)\n",
      "tensor(237)\n",
      "tensor(208)\n",
      "tensor(14)\n",
      "tensor(65)\n",
      "tensor(63)\n",
      "tensor(149)\n",
      "tensor(263)\n",
      "tensor(113)\n",
      "tensor(295)\n",
      "tensor(273)\n",
      "tensor(187)\n",
      "tensor(56)\n",
      "tensor(0)\n",
      "tensor(250)\n",
      "tensor(127)\n",
      "tensor(274)\n",
      "tensor(151)\n",
      "tensor(209)\n",
      "tensor(24)\n",
      "tensor(10)\n",
      "tensor(230)\n",
      "tensor(276)\n",
      "tensor(106)\n",
      "tensor(231)\n",
      "tensor(211)\n",
      "tensor(201)\n",
      "tensor(36)\n",
      "tensor(53)\n",
      "tensor(223)\n",
      "tensor(155)\n",
      "tensor(165)\n",
      "tensor(17)\n",
      "tensor(120)\n",
      "tensor(216)\n",
      "tensor(238)\n",
      "tensor(148)\n",
      "tensor(3)\n",
      "tensor(13)\n",
      "tensor(259)\n",
      "tensor(152)\n",
      "tensor(6)\n",
      "tensor(110)\n",
      "tensor(206)\n",
      "tensor(128)\n",
      "tensor(40)\n",
      "tensor(247)\n",
      "tensor(270)\n",
      "tensor(166)\n",
      "tensor(171)\n",
      "tensor(194)\n",
      "tensor(103)\n",
      "tensor(181)\n",
      "tensor(267)\n",
      "tensor(1)\n",
      "tensor(76)\n",
      "tensor(196)\n",
      "tensor(134)\n",
      "tensor(284)\n",
      "tensor(191)\n",
      "tensor(256)\n",
      "tensor(80)\n",
      "tensor(102)\n",
      "tensor(294)\n",
      "tensor(157)\n",
      "tensor(176)\n",
      "tensor(156)\n",
      "tensor(62)\n",
      "tensor(5)\n",
      "tensor(72)\n",
      "tensor(285)\n",
      "tensor(91)\n",
      "tensor(163)\n",
      "tensor(277)\n",
      "tensor(28)\n",
      "tensor(87)\n",
      "tensor(261)\n",
      "tensor(137)\n",
      "tensor(150)\n",
      "tensor(229)\n",
      "tensor(121)\n",
      "tensor(129)\n",
      "tensor(161)\n",
      "tensor(170)\n",
      "tensor(275)\n",
      "tensor(219)\n",
      "tensor(212)\n",
      "tensor(249)\n",
      "tensor(39)\n",
      "tensor(239)\n",
      "tensor(235)\n",
      "tensor(97)\n",
      "tensor(131)\n",
      "tensor(115)\n",
      "tensor(174)\n",
      "tensor(107)\n",
      "tensor(52)\n",
      "tensor(266)\n",
      "tensor(33)\n",
      "tensor(116)\n",
      "tensor(81)\n",
      "tensor(251)\n",
      "tensor(138)\n",
      "tensor(179)\n",
      "tensor(45)\n",
      "tensor(101)\n",
      "tensor(60)\n",
      "tensor(19)\n",
      "tensor(204)\n",
      "tensor(48)\n",
      "tensor(297)\n",
      "tensor(243)\n",
      "tensor(12)\n",
      "tensor(18)\n",
      "tensor(67)\n",
      "tensor(68)\n",
      "tensor(44)\n",
      "tensor(260)\n",
      "tensor(268)\n",
      "tensor(74)\n",
      "tensor(192)\n",
      "tensor(55)\n",
      "tensor(57)\n",
      "tensor(29)\n",
      "tensor(70)\n",
      "tensor(207)\n",
      "tensor(9)\n",
      "tensor(175)\n",
      "tensor(142)\n",
      "tensor(125)\n",
      "tensor(245)\n",
      "tensor(180)\n",
      "tensor(117)\n",
      "tensor(58)\n",
      "tensor(167)\n",
      "tensor(146)\n",
      "tensor(193)\n",
      "tensor(242)\n",
      "tensor(287)\n",
      "tensor(258)\n",
      "tensor(292)\n",
      "tensor(190)\n",
      "tensor(26)\n",
      "tensor(123)\n",
      "tensor(221)\n",
      "tensor(199)\n",
      "tensor(215)\n",
      "tensor(126)\n",
      "tensor(173)\n",
      "tensor(291)\n",
      "tensor(188)\n",
      "tensor(111)\n",
      "tensor(178)\n",
      "tensor(92)\n",
      "tensor(296)\n",
      "tensor(64)\n",
      "tensor(144)\n",
      "tensor(213)\n",
      "tensor(75)\n",
      "tensor(262)\n",
      "tensor(108)\n",
      "tensor(184)\n",
      "tensor(203)\n",
      "tensor(248)\n",
      "tensor(233)\n",
      "tensor(104)\n",
      "tensor(73)\n",
      "tensor(252)\n",
      "tensor(51)\n",
      "tensor(269)\n",
      "tensor(299)\n",
      "tensor(114)\n",
      "tensor(122)\n",
      "tensor(272)\n",
      "tensor(59)\n",
      "tensor(105)\n",
      "tensor(195)\n",
      "tensor(220)\n",
      "tensor(228)\n",
      "tensor(197)\n",
      "tensor(37)\n",
      "tensor(143)\n",
      "tensor(162)\n",
      "tensor(226)\n",
      "tensor(227)\n",
      "tensor(290)\n",
      "tensor(8)\n",
      "tensor(255)\n",
      "tensor(232)\n",
      "tensor(118)\n",
      "tensor(31)\n",
      "tensor(225)\n",
      "tensor(130)\n",
      "tensor(264)\n",
      "tensor(280)\n",
      "tensor(224)\n",
      "tensor(271)\n",
      "tensor(236)\n",
      "tensor(147)\n",
      "tensor(189)\n",
      "tensor(32)\n",
      "tensor(293)\n",
      "tensor(185)\n",
      "tensor(278)\n",
      "tensor(85)\n",
      "tensor(100)\n",
      "tensor(88)\n",
      "tensor(11)\n",
      "tensor(119)\n",
      "tensor(34)\n",
      "tensor(47)\n",
      "tensor(214)\n",
      "tensor(153)\n",
      "tensor(79)\n",
      "tensor(135)\n",
      "tensor(140)\n",
      "tensor(168)\n",
      "tensor(133)\n",
      "tensor(240)\n",
      "tensor(99)\n",
      "tensor(288)\n",
      "tensor(136)\n",
      "tensor(217)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "240"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 0 \n",
    "for i in train_idx:\n",
    "    print(i)\n",
    "    a = a + 1\n",
    "\n",
    "a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
