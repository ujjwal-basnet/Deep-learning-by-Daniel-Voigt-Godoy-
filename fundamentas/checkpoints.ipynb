{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import numpy as np\n",
    "from torch.utils.tensorboard import SummaryWriter \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i data_preparation/v2.py\n",
    "%run -i model_configuration/v3.py\n",
    "%run -i model_training/v5.py\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epoch': 200,\n",
       " 'model_state_dict': OrderedDict([('0.weight',\n",
       "               tensor([[2.0392]], device='cuda:0')),\n",
       "              ('0.bias', tensor([9.7361], device='cuda:0'))]),\n",
       " 'optimizer_state_dict': {'state': {0: {'momentum_buffer': None},\n",
       "   1: {'momentum_buffer': None}},\n",
       "  'param_groups': [{'lr': 0.01,\n",
       "    'momentum': 0,\n",
       "    'dampening': 0,\n",
       "    'weight_decay': 0,\n",
       "    'nesterov': False,\n",
       "    'maximize': False,\n",
       "    'foreach': None,\n",
       "    'differentiable': False,\n",
       "    'fused': None,\n",
       "    'params': [0, 1]}]},\n",
       " 'loss': [18.321563720703125,\n",
       "  15.284608840942383,\n",
       "  12.605552673339844,\n",
       "  14.131032943725586,\n",
       "  10.50120735168457,\n",
       "  13.305618286132812,\n",
       "  13.559293746948242,\n",
       "  10.164419174194336,\n",
       "  11.771122932434082,\n",
       "  8.442937850952148,\n",
       "  10.343616485595703,\n",
       "  9.65005874633789,\n",
       "  9.756438255310059,\n",
       "  12.474502563476562,\n",
       "  7.038472652435303,\n",
       "  7.063415050506592,\n",
       "  5.952693462371826,\n",
       "  4.232982635498047,\n",
       "  7.292891502380371,\n",
       "  9.461960792541504,\n",
       "  5.070512771606445,\n",
       "  7.919191360473633,\n",
       "  6.747104644775391,\n",
       "  7.826556205749512,\n",
       "  8.145875930786133,\n",
       "  7.038415908813477,\n",
       "  5.466849327087402,\n",
       "  5.519520282745361,\n",
       "  4.868703842163086,\n",
       "  4.67139196395874,\n",
       "  5.287670135498047,\n",
       "  3.897853374481201,\n",
       "  3.5627336502075195,\n",
       "  3.66573429107666,\n",
       "  2.5699257850646973,\n",
       "  3.3599166870117188,\n",
       "  4.605118751525879,\n",
       "  4.273742198944092,\n",
       "  3.0415401458740234,\n",
       "  3.5260324478149414,\n",
       "  1.8254027366638184,\n",
       "  4.570296764373779,\n",
       "  3.2576286792755127,\n",
       "  2.320406198501587,\n",
       "  2.989206314086914,\n",
       "  3.082038402557373,\n",
       "  2.54247784614563,\n",
       "  1.833512544631958,\n",
       "  1.9076168537139893,\n",
       "  2.1624386310577393,\n",
       "  1.4667608737945557,\n",
       "  3.093172073364258,\n",
       "  2.7996749877929688,\n",
       "  2.156743049621582,\n",
       "  2.1083340644836426,\n",
       "  2.5859642028808594,\n",
       "  1.466341495513916,\n",
       "  2.243035316467285,\n",
       "  1.6419090032577515,\n",
       "  1.3090426921844482,\n",
       "  2.2157297134399414,\n",
       "  1.2821329832077026,\n",
       "  2.5716214179992676,\n",
       "  1.7677451372146606,\n",
       "  1.173338532447815,\n",
       "  1.8870609998703003,\n",
       "  1.3260537385940552,\n",
       "  0.8695800304412842,\n",
       "  1.6796917915344238,\n",
       "  1.352823257446289,\n",
       "  1.5219722986221313,\n",
       "  1.1185888051986694,\n",
       "  0.9314736127853394,\n",
       "  0.7072933316230774,\n",
       "  0.8203402757644653,\n",
       "  1.2734944820404053,\n",
       "  0.8616583347320557,\n",
       "  1.1068315505981445,\n",
       "  0.9026134610176086,\n",
       "  0.5950921177864075,\n",
       "  0.5402188301086426,\n",
       "  0.9986152052879333,\n",
       "  0.5472594499588013,\n",
       "  0.8174896240234375,\n",
       "  0.920310914516449,\n",
       "  0.7475989460945129,\n",
       "  0.907094419002533,\n",
       "  0.5996668338775635,\n",
       "  0.5813297033309937,\n",
       "  0.8864921927452087,\n",
       "  0.5811204314231873,\n",
       "  0.6702264547348022,\n",
       "  0.5191553235054016,\n",
       "  0.36927807331085205,\n",
       "  0.35366547107696533,\n",
       "  0.47967368364334106,\n",
       "  0.5042386054992676,\n",
       "  0.3414058983325958,\n",
       "  0.5251876711845398,\n",
       "  0.42514321208000183,\n",
       "  0.32897046208381653,\n",
       "  0.3995399475097656,\n",
       "  0.48065468668937683,\n",
       "  0.17813067138195038,\n",
       "  0.42821574211120605,\n",
       "  0.5635722875595093,\n",
       "  0.3869224786758423,\n",
       "  0.4688558578491211,\n",
       "  0.2680094242095947,\n",
       "  0.43485110998153687,\n",
       "  0.31874826550483704,\n",
       "  0.2510468065738678,\n",
       "  0.33034878969192505,\n",
       "  0.2772446870803833,\n",
       "  0.2706785202026367,\n",
       "  0.233164981007576,\n",
       "  0.17447426915168762,\n",
       "  0.21930108964443207,\n",
       "  0.29349684715270996,\n",
       "  0.2181740403175354,\n",
       "  0.18217281997203827,\n",
       "  0.1902029812335968,\n",
       "  0.20303422212600708,\n",
       "  0.18656960129737854,\n",
       "  0.19788607954978943,\n",
       "  0.15889818966388702,\n",
       "  0.29695987701416016,\n",
       "  0.21631115674972534,\n",
       "  0.15635210275650024,\n",
       "  0.19126084446907043,\n",
       "  0.10600936412811279,\n",
       "  0.08837951719760895,\n",
       "  0.0917721688747406,\n",
       "  0.1213608980178833,\n",
       "  0.06985776126384735,\n",
       "  0.13478043675422668,\n",
       "  0.10981674492359161,\n",
       "  0.10555168986320496,\n",
       "  0.11016879230737686,\n",
       "  0.10370851308107376,\n",
       "  0.13841527700424194,\n",
       "  0.10016961395740509,\n",
       "  0.09898863732814789,\n",
       "  0.11715497821569443,\n",
       "  0.15598329901695251,\n",
       "  0.08264777064323425,\n",
       "  0.09623082727193832,\n",
       "  0.08691070973873138,\n",
       "  0.06961008906364441,\n",
       "  0.07035414129495621,\n",
       "  0.07262668013572693,\n",
       "  0.04355253651738167,\n",
       "  0.06457994878292084,\n",
       "  0.05041572451591492,\n",
       "  0.07082916796207428,\n",
       "  0.046462882310152054,\n",
       "  0.045440465211868286,\n",
       "  0.049343738704919815,\n",
       "  0.05081440880894661,\n",
       "  0.050942741334438324,\n",
       "  0.03602612018585205,\n",
       "  0.06329293549060822,\n",
       "  0.027776777744293213,\n",
       "  0.03342738747596741,\n",
       "  0.037792835384607315,\n",
       "  0.05015949532389641,\n",
       "  0.059111759066581726,\n",
       "  0.019763337448239326,\n",
       "  0.04074505716562271,\n",
       "  0.04090305417776108,\n",
       "  0.03217922896146774,\n",
       "  0.03079107031226158,\n",
       "  0.036010757088661194,\n",
       "  0.032930709421634674,\n",
       "  0.03456718474626541,\n",
       "  0.025318846106529236,\n",
       "  0.02401033230125904,\n",
       "  0.027003884315490723,\n",
       "  0.036231741309165955,\n",
       "  0.039992231875658035,\n",
       "  0.021367978304624557,\n",
       "  0.0267472006380558,\n",
       "  0.025566373020410538,\n",
       "  0.0221928209066391,\n",
       "  0.022939035668969154,\n",
       "  0.025050222873687744,\n",
       "  0.03445326164364815,\n",
       "  0.028598185628652573,\n",
       "  0.027736201882362366,\n",
       "  0.02059021033346653,\n",
       "  0.0244482159614563,\n",
       "  0.015043162740767002,\n",
       "  0.013170632533729076,\n",
       "  0.014459815807640553,\n",
       "  0.01865386962890625,\n",
       "  0.016032354906201363,\n",
       "  0.017402924597263336,\n",
       "  0.017798375338315964,\n",
       "  0.012873444706201553,\n",
       "  0.008831968531012535],\n",
       " 'val_loss': [13.01761531829834,\n",
       "  12.142864227294922,\n",
       "  11.737434387207031,\n",
       "  11.29543685913086,\n",
       "  11.164144515991211,\n",
       "  10.935464859008789,\n",
       "  10.160937309265137,\n",
       "  9.986320495605469,\n",
       "  9.548952102661133,\n",
       "  9.235998153686523,\n",
       "  8.848620414733887,\n",
       "  9.012624740600586,\n",
       "  8.684398651123047,\n",
       "  8.189977645874023,\n",
       "  7.786935806274414,\n",
       "  7.485403537750244,\n",
       "  7.512032508850098,\n",
       "  6.963658332824707,\n",
       "  6.726258277893066,\n",
       "  6.476142883300781,\n",
       "  6.408239364624023,\n",
       "  6.016504764556885,\n",
       "  5.8221330642700195,\n",
       "  5.607302665710449,\n",
       "  5.442389488220215,\n",
       "  5.21760368347168,\n",
       "  5.241485595703125,\n",
       "  4.958794116973877,\n",
       "  4.884615898132324,\n",
       "  4.537417888641357,\n",
       "  4.437025547027588,\n",
       "  4.611785888671875,\n",
       "  4.589730262756348,\n",
       "  3.9818577766418457,\n",
       "  3.8117971420288086,\n",
       "  3.903719425201416,\n",
       "  3.5498595237731934,\n",
       "  3.491483688354492,\n",
       "  3.3588733673095703,\n",
       "  3.2139108180999756,\n",
       "  3.2968740463256836,\n",
       "  2.980722188949585,\n",
       "  2.9114339351654053,\n",
       "  2.7950732707977295,\n",
       "  2.710480213165283,\n",
       "  2.7068934440612793,\n",
       "  2.5611746311187744,\n",
       "  2.501126527786255,\n",
       "  2.334658145904541,\n",
       "  2.2528066635131836,\n",
       "  2.3167612552642822,\n",
       "  2.1648550033569336,\n",
       "  2.115492820739746,\n",
       "  1.9629909992218018,\n",
       "  1.8888201713562012,\n",
       "  1.8768806457519531,\n",
       "  1.7838008403778076,\n",
       "  1.7080914974212646,\n",
       "  1.7179006338119507,\n",
       "  1.6599044799804688,\n",
       "  1.5854077339172363,\n",
       "  1.4937775135040283,\n",
       "  1.428501844406128,\n",
       "  1.3865137100219727,\n",
       "  1.3739770650863647,\n",
       "  1.3292957544326782,\n",
       "  1.2702314853668213,\n",
       "  1.2804250717163086,\n",
       "  1.159132957458496,\n",
       "  1.1217796802520752,\n",
       "  1.0840506553649902,\n",
       "  1.0575294494628906,\n",
       "  1.0133637189865112,\n",
       "  0.9722521305084229,\n",
       "  0.9393011331558228,\n",
       "  0.906629204750061,\n",
       "  0.8784433603286743,\n",
       "  0.8517321348190308,\n",
       "  0.816088855266571,\n",
       "  0.7999518513679504,\n",
       "  0.7768117785453796,\n",
       "  0.7435864210128784,\n",
       "  0.7408850193023682,\n",
       "  0.7016827464103699,\n",
       "  0.6620433926582336,\n",
       "  0.65250563621521,\n",
       "  0.6211972832679749,\n",
       "  0.5968007445335388,\n",
       "  0.5875036716461182,\n",
       "  0.6299636363983154,\n",
       "  0.5422550439834595,\n",
       "  0.5249764323234558,\n",
       "  0.5028814077377319,\n",
       "  0.4941064417362213,\n",
       "  0.4698609411716461,\n",
       "  0.489202618598938,\n",
       "  0.43475186824798584,\n",
       "  0.4439598023891449,\n",
       "  0.5025240778923035,\n",
       "  0.40436142683029175,\n",
       "  0.3824172019958496,\n",
       "  0.36603060364723206,\n",
       "  0.3524690270423889,\n",
       "  0.3784789741039276,\n",
       "  0.32898274064064026,\n",
       "  0.32004645466804504,\n",
       "  0.3148993253707886,\n",
       "  0.3251533508300781,\n",
       "  0.2927956283092499,\n",
       "  0.28247618675231934,\n",
       "  0.26721709966659546,\n",
       "  0.2627723515033722,\n",
       "  0.25442788004875183,\n",
       "  0.2741752862930298,\n",
       "  0.23240399360656738,\n",
       "  0.22318464517593384,\n",
       "  0.21885263919830322,\n",
       "  0.2091241478919983,\n",
       "  0.20127512514591217,\n",
       "  0.19422119855880737,\n",
       "  0.19437339901924133,\n",
       "  0.18688693642616272,\n",
       "  0.17508259415626526,\n",
       "  0.17073841392993927,\n",
       "  0.16438651084899902,\n",
       "  0.15756797790527344,\n",
       "  0.15160046517848969,\n",
       "  0.14983928203582764,\n",
       "  0.1453687697649002,\n",
       "  0.1391470730304718,\n",
       "  0.13279424607753754,\n",
       "  0.14415234327316284,\n",
       "  0.12489978969097137,\n",
       "  0.1203833669424057,\n",
       "  0.11768417060375214,\n",
       "  0.11163709312677383,\n",
       "  0.10793597996234894,\n",
       "  0.10324475914239883,\n",
       "  0.09958970546722412,\n",
       "  0.11341428756713867,\n",
       "  0.094225212931633,\n",
       "  0.08966679871082306,\n",
       "  0.08727490901947021,\n",
       "  0.08527626097202301,\n",
       "  0.08076772838830948,\n",
       "  0.07820571959018707,\n",
       "  0.07552821189165115,\n",
       "  0.07554003596305847,\n",
       "  0.07023635506629944,\n",
       "  0.06959877908229828,\n",
       "  0.06556610763072968,\n",
       "  0.06324592232704163,\n",
       "  0.06425412744283676,\n",
       "  0.06975424289703369,\n",
       "  0.05782712996006012,\n",
       "  0.05661773681640625,\n",
       "  0.053556058555841446,\n",
       "  0.051220301538705826,\n",
       "  0.04983026534318924,\n",
       "  0.048868946731090546,\n",
       "  0.047256093472242355,\n",
       "  0.04454974830150604,\n",
       "  0.043007075786590576,\n",
       "  0.042452067136764526,\n",
       "  0.040150705724954605,\n",
       "  0.040836796164512634,\n",
       "  0.037850115448236465,\n",
       "  0.03616950660943985,\n",
       "  0.035018205642700195,\n",
       "  0.034388069063425064,\n",
       "  0.032441701740026474,\n",
       "  0.032831549644470215,\n",
       "  0.033327165991067886,\n",
       "  0.029194030910730362,\n",
       "  0.028697045519948006,\n",
       "  0.02726825140416622,\n",
       "  0.026403743773698807,\n",
       "  0.025426654145121574,\n",
       "  0.02456745319068432,\n",
       "  0.024305786937475204,\n",
       "  0.022838883101940155,\n",
       "  0.022121887654066086,\n",
       "  0.021338241174817085,\n",
       "  0.02062804251909256,\n",
       "  0.01989779993891716,\n",
       "  0.019191456958651543,\n",
       "  0.018502945080399513,\n",
       "  0.017903022468090057,\n",
       "  0.01726016029715538,\n",
       "  0.016938278451561928,\n",
       "  0.017381753772497177,\n",
       "  0.015522290021181107,\n",
       "  0.015015050768852234,\n",
       "  0.014453533105552197,\n",
       "  0.01410122960805893,\n",
       "  0.013555246405303478,\n",
       "  0.013071177527308464,\n",
       "  0.012617276981472969,\n",
       "  0.012762017548084259,\n",
       "  0.011787133291363716]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save \n",
    "#save \n",
    "checkpoint = {'epoch' : n_epochs , \n",
    "              'model_state_dict' : model.state_dict() , \n",
    "              'optimizer_state_dict': optimizer.state_dict() , \n",
    "              'loss': losses , \n",
    "              'val_loss' : val_losses}\n",
    "\n",
    "checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save \n",
    "torch.save(checkpoint , 'model_checkpoint.pth') #creates model_checkpoint.pth file  pth = pytorch \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## we save  the checkpoint what about loadin it back "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now run data prepreation and confifuration \n",
    "%run -i data_preparation/v2.py\n",
    "%run -i model_configuration/v3.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('0.weight', tensor([[0.7645]], device='cuda:0')),\n",
       "             ('0.bias', tensor([0.8300], device='cuda:0'))])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that we have untrain model\n",
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#load the dictionary back using torch.load()\n",
    "#load model and optimizer state dictionaries back using load stae dict () \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epoch': 200,\n",
       " 'model_state_dict': OrderedDict([('0.weight',\n",
       "               tensor([[2.0392]], device='cuda:0')),\n",
       "              ('0.bias', tensor([9.7361], device='cuda:0'))]),\n",
       " 'optimizer_state_dict': {'state': {0: {'momentum_buffer': None},\n",
       "   1: {'momentum_buffer': None}},\n",
       "  'param_groups': [{'lr': 0.01,\n",
       "    'momentum': 0,\n",
       "    'dampening': 0,\n",
       "    'weight_decay': 0,\n",
       "    'nesterov': False,\n",
       "    'maximize': False,\n",
       "    'foreach': None,\n",
       "    'differentiable': False,\n",
       "    'fused': None,\n",
       "    'params': [0, 1]}]},\n",
       " 'loss': [18.321563720703125,\n",
       "  15.284608840942383,\n",
       "  12.605552673339844,\n",
       "  14.131032943725586,\n",
       "  10.50120735168457,\n",
       "  13.305618286132812,\n",
       "  13.559293746948242,\n",
       "  10.164419174194336,\n",
       "  11.771122932434082,\n",
       "  8.442937850952148,\n",
       "  10.343616485595703,\n",
       "  9.65005874633789,\n",
       "  9.756438255310059,\n",
       "  12.474502563476562,\n",
       "  7.038472652435303,\n",
       "  7.063415050506592,\n",
       "  5.952693462371826,\n",
       "  4.232982635498047,\n",
       "  7.292891502380371,\n",
       "  9.461960792541504,\n",
       "  5.070512771606445,\n",
       "  7.919191360473633,\n",
       "  6.747104644775391,\n",
       "  7.826556205749512,\n",
       "  8.145875930786133,\n",
       "  7.038415908813477,\n",
       "  5.466849327087402,\n",
       "  5.519520282745361,\n",
       "  4.868703842163086,\n",
       "  4.67139196395874,\n",
       "  5.287670135498047,\n",
       "  3.897853374481201,\n",
       "  3.5627336502075195,\n",
       "  3.66573429107666,\n",
       "  2.5699257850646973,\n",
       "  3.3599166870117188,\n",
       "  4.605118751525879,\n",
       "  4.273742198944092,\n",
       "  3.0415401458740234,\n",
       "  3.5260324478149414,\n",
       "  1.8254027366638184,\n",
       "  4.570296764373779,\n",
       "  3.2576286792755127,\n",
       "  2.320406198501587,\n",
       "  2.989206314086914,\n",
       "  3.082038402557373,\n",
       "  2.54247784614563,\n",
       "  1.833512544631958,\n",
       "  1.9076168537139893,\n",
       "  2.1624386310577393,\n",
       "  1.4667608737945557,\n",
       "  3.093172073364258,\n",
       "  2.7996749877929688,\n",
       "  2.156743049621582,\n",
       "  2.1083340644836426,\n",
       "  2.5859642028808594,\n",
       "  1.466341495513916,\n",
       "  2.243035316467285,\n",
       "  1.6419090032577515,\n",
       "  1.3090426921844482,\n",
       "  2.2157297134399414,\n",
       "  1.2821329832077026,\n",
       "  2.5716214179992676,\n",
       "  1.7677451372146606,\n",
       "  1.173338532447815,\n",
       "  1.8870609998703003,\n",
       "  1.3260537385940552,\n",
       "  0.8695800304412842,\n",
       "  1.6796917915344238,\n",
       "  1.352823257446289,\n",
       "  1.5219722986221313,\n",
       "  1.1185888051986694,\n",
       "  0.9314736127853394,\n",
       "  0.7072933316230774,\n",
       "  0.8203402757644653,\n",
       "  1.2734944820404053,\n",
       "  0.8616583347320557,\n",
       "  1.1068315505981445,\n",
       "  0.9026134610176086,\n",
       "  0.5950921177864075,\n",
       "  0.5402188301086426,\n",
       "  0.9986152052879333,\n",
       "  0.5472594499588013,\n",
       "  0.8174896240234375,\n",
       "  0.920310914516449,\n",
       "  0.7475989460945129,\n",
       "  0.907094419002533,\n",
       "  0.5996668338775635,\n",
       "  0.5813297033309937,\n",
       "  0.8864921927452087,\n",
       "  0.5811204314231873,\n",
       "  0.6702264547348022,\n",
       "  0.5191553235054016,\n",
       "  0.36927807331085205,\n",
       "  0.35366547107696533,\n",
       "  0.47967368364334106,\n",
       "  0.5042386054992676,\n",
       "  0.3414058983325958,\n",
       "  0.5251876711845398,\n",
       "  0.42514321208000183,\n",
       "  0.32897046208381653,\n",
       "  0.3995399475097656,\n",
       "  0.48065468668937683,\n",
       "  0.17813067138195038,\n",
       "  0.42821574211120605,\n",
       "  0.5635722875595093,\n",
       "  0.3869224786758423,\n",
       "  0.4688558578491211,\n",
       "  0.2680094242095947,\n",
       "  0.43485110998153687,\n",
       "  0.31874826550483704,\n",
       "  0.2510468065738678,\n",
       "  0.33034878969192505,\n",
       "  0.2772446870803833,\n",
       "  0.2706785202026367,\n",
       "  0.233164981007576,\n",
       "  0.17447426915168762,\n",
       "  0.21930108964443207,\n",
       "  0.29349684715270996,\n",
       "  0.2181740403175354,\n",
       "  0.18217281997203827,\n",
       "  0.1902029812335968,\n",
       "  0.20303422212600708,\n",
       "  0.18656960129737854,\n",
       "  0.19788607954978943,\n",
       "  0.15889818966388702,\n",
       "  0.29695987701416016,\n",
       "  0.21631115674972534,\n",
       "  0.15635210275650024,\n",
       "  0.19126084446907043,\n",
       "  0.10600936412811279,\n",
       "  0.08837951719760895,\n",
       "  0.0917721688747406,\n",
       "  0.1213608980178833,\n",
       "  0.06985776126384735,\n",
       "  0.13478043675422668,\n",
       "  0.10981674492359161,\n",
       "  0.10555168986320496,\n",
       "  0.11016879230737686,\n",
       "  0.10370851308107376,\n",
       "  0.13841527700424194,\n",
       "  0.10016961395740509,\n",
       "  0.09898863732814789,\n",
       "  0.11715497821569443,\n",
       "  0.15598329901695251,\n",
       "  0.08264777064323425,\n",
       "  0.09623082727193832,\n",
       "  0.08691070973873138,\n",
       "  0.06961008906364441,\n",
       "  0.07035414129495621,\n",
       "  0.07262668013572693,\n",
       "  0.04355253651738167,\n",
       "  0.06457994878292084,\n",
       "  0.05041572451591492,\n",
       "  0.07082916796207428,\n",
       "  0.046462882310152054,\n",
       "  0.045440465211868286,\n",
       "  0.049343738704919815,\n",
       "  0.05081440880894661,\n",
       "  0.050942741334438324,\n",
       "  0.03602612018585205,\n",
       "  0.06329293549060822,\n",
       "  0.027776777744293213,\n",
       "  0.03342738747596741,\n",
       "  0.037792835384607315,\n",
       "  0.05015949532389641,\n",
       "  0.059111759066581726,\n",
       "  0.019763337448239326,\n",
       "  0.04074505716562271,\n",
       "  0.04090305417776108,\n",
       "  0.03217922896146774,\n",
       "  0.03079107031226158,\n",
       "  0.036010757088661194,\n",
       "  0.032930709421634674,\n",
       "  0.03456718474626541,\n",
       "  0.025318846106529236,\n",
       "  0.02401033230125904,\n",
       "  0.027003884315490723,\n",
       "  0.036231741309165955,\n",
       "  0.039992231875658035,\n",
       "  0.021367978304624557,\n",
       "  0.0267472006380558,\n",
       "  0.025566373020410538,\n",
       "  0.0221928209066391,\n",
       "  0.022939035668969154,\n",
       "  0.025050222873687744,\n",
       "  0.03445326164364815,\n",
       "  0.028598185628652573,\n",
       "  0.027736201882362366,\n",
       "  0.02059021033346653,\n",
       "  0.0244482159614563,\n",
       "  0.015043162740767002,\n",
       "  0.013170632533729076,\n",
       "  0.014459815807640553,\n",
       "  0.01865386962890625,\n",
       "  0.016032354906201363,\n",
       "  0.017402924597263336,\n",
       "  0.017798375338315964,\n",
       "  0.012873444706201553,\n",
       "  0.008831968531012535],\n",
       " 'val_loss': [13.01761531829834,\n",
       "  12.142864227294922,\n",
       "  11.737434387207031,\n",
       "  11.29543685913086,\n",
       "  11.164144515991211,\n",
       "  10.935464859008789,\n",
       "  10.160937309265137,\n",
       "  9.986320495605469,\n",
       "  9.548952102661133,\n",
       "  9.235998153686523,\n",
       "  8.848620414733887,\n",
       "  9.012624740600586,\n",
       "  8.684398651123047,\n",
       "  8.189977645874023,\n",
       "  7.786935806274414,\n",
       "  7.485403537750244,\n",
       "  7.512032508850098,\n",
       "  6.963658332824707,\n",
       "  6.726258277893066,\n",
       "  6.476142883300781,\n",
       "  6.408239364624023,\n",
       "  6.016504764556885,\n",
       "  5.8221330642700195,\n",
       "  5.607302665710449,\n",
       "  5.442389488220215,\n",
       "  5.21760368347168,\n",
       "  5.241485595703125,\n",
       "  4.958794116973877,\n",
       "  4.884615898132324,\n",
       "  4.537417888641357,\n",
       "  4.437025547027588,\n",
       "  4.611785888671875,\n",
       "  4.589730262756348,\n",
       "  3.9818577766418457,\n",
       "  3.8117971420288086,\n",
       "  3.903719425201416,\n",
       "  3.5498595237731934,\n",
       "  3.491483688354492,\n",
       "  3.3588733673095703,\n",
       "  3.2139108180999756,\n",
       "  3.2968740463256836,\n",
       "  2.980722188949585,\n",
       "  2.9114339351654053,\n",
       "  2.7950732707977295,\n",
       "  2.710480213165283,\n",
       "  2.7068934440612793,\n",
       "  2.5611746311187744,\n",
       "  2.501126527786255,\n",
       "  2.334658145904541,\n",
       "  2.2528066635131836,\n",
       "  2.3167612552642822,\n",
       "  2.1648550033569336,\n",
       "  2.115492820739746,\n",
       "  1.9629909992218018,\n",
       "  1.8888201713562012,\n",
       "  1.8768806457519531,\n",
       "  1.7838008403778076,\n",
       "  1.7080914974212646,\n",
       "  1.7179006338119507,\n",
       "  1.6599044799804688,\n",
       "  1.5854077339172363,\n",
       "  1.4937775135040283,\n",
       "  1.428501844406128,\n",
       "  1.3865137100219727,\n",
       "  1.3739770650863647,\n",
       "  1.3292957544326782,\n",
       "  1.2702314853668213,\n",
       "  1.2804250717163086,\n",
       "  1.159132957458496,\n",
       "  1.1217796802520752,\n",
       "  1.0840506553649902,\n",
       "  1.0575294494628906,\n",
       "  1.0133637189865112,\n",
       "  0.9722521305084229,\n",
       "  0.9393011331558228,\n",
       "  0.906629204750061,\n",
       "  0.8784433603286743,\n",
       "  0.8517321348190308,\n",
       "  0.816088855266571,\n",
       "  0.7999518513679504,\n",
       "  0.7768117785453796,\n",
       "  0.7435864210128784,\n",
       "  0.7408850193023682,\n",
       "  0.7016827464103699,\n",
       "  0.6620433926582336,\n",
       "  0.65250563621521,\n",
       "  0.6211972832679749,\n",
       "  0.5968007445335388,\n",
       "  0.5875036716461182,\n",
       "  0.6299636363983154,\n",
       "  0.5422550439834595,\n",
       "  0.5249764323234558,\n",
       "  0.5028814077377319,\n",
       "  0.4941064417362213,\n",
       "  0.4698609411716461,\n",
       "  0.489202618598938,\n",
       "  0.43475186824798584,\n",
       "  0.4439598023891449,\n",
       "  0.5025240778923035,\n",
       "  0.40436142683029175,\n",
       "  0.3824172019958496,\n",
       "  0.36603060364723206,\n",
       "  0.3524690270423889,\n",
       "  0.3784789741039276,\n",
       "  0.32898274064064026,\n",
       "  0.32004645466804504,\n",
       "  0.3148993253707886,\n",
       "  0.3251533508300781,\n",
       "  0.2927956283092499,\n",
       "  0.28247618675231934,\n",
       "  0.26721709966659546,\n",
       "  0.2627723515033722,\n",
       "  0.25442788004875183,\n",
       "  0.2741752862930298,\n",
       "  0.23240399360656738,\n",
       "  0.22318464517593384,\n",
       "  0.21885263919830322,\n",
       "  0.2091241478919983,\n",
       "  0.20127512514591217,\n",
       "  0.19422119855880737,\n",
       "  0.19437339901924133,\n",
       "  0.18688693642616272,\n",
       "  0.17508259415626526,\n",
       "  0.17073841392993927,\n",
       "  0.16438651084899902,\n",
       "  0.15756797790527344,\n",
       "  0.15160046517848969,\n",
       "  0.14983928203582764,\n",
       "  0.1453687697649002,\n",
       "  0.1391470730304718,\n",
       "  0.13279424607753754,\n",
       "  0.14415234327316284,\n",
       "  0.12489978969097137,\n",
       "  0.1203833669424057,\n",
       "  0.11768417060375214,\n",
       "  0.11163709312677383,\n",
       "  0.10793597996234894,\n",
       "  0.10324475914239883,\n",
       "  0.09958970546722412,\n",
       "  0.11341428756713867,\n",
       "  0.094225212931633,\n",
       "  0.08966679871082306,\n",
       "  0.08727490901947021,\n",
       "  0.08527626097202301,\n",
       "  0.08076772838830948,\n",
       "  0.07820571959018707,\n",
       "  0.07552821189165115,\n",
       "  0.07554003596305847,\n",
       "  0.07023635506629944,\n",
       "  0.06959877908229828,\n",
       "  0.06556610763072968,\n",
       "  0.06324592232704163,\n",
       "  0.06425412744283676,\n",
       "  0.06975424289703369,\n",
       "  0.05782712996006012,\n",
       "  0.05661773681640625,\n",
       "  0.053556058555841446,\n",
       "  0.051220301538705826,\n",
       "  0.04983026534318924,\n",
       "  0.048868946731090546,\n",
       "  0.047256093472242355,\n",
       "  0.04454974830150604,\n",
       "  0.043007075786590576,\n",
       "  0.042452067136764526,\n",
       "  0.040150705724954605,\n",
       "  0.040836796164512634,\n",
       "  0.037850115448236465,\n",
       "  0.03616950660943985,\n",
       "  0.035018205642700195,\n",
       "  0.034388069063425064,\n",
       "  0.032441701740026474,\n",
       "  0.032831549644470215,\n",
       "  0.033327165991067886,\n",
       "  0.029194030910730362,\n",
       "  0.028697045519948006,\n",
       "  0.02726825140416622,\n",
       "  0.026403743773698807,\n",
       "  0.025426654145121574,\n",
       "  0.02456745319068432,\n",
       "  0.024305786937475204,\n",
       "  0.022838883101940155,\n",
       "  0.022121887654066086,\n",
       "  0.021338241174817085,\n",
       "  0.02062804251909256,\n",
       "  0.01989779993891716,\n",
       "  0.019191456958651543,\n",
       "  0.018502945080399513,\n",
       "  0.017903022468090057,\n",
       "  0.01726016029715538,\n",
       "  0.016938278451561928,\n",
       "  0.017381753772497177,\n",
       "  0.015522290021181107,\n",
       "  0.015015050768852234,\n",
       "  0.014453533105552197,\n",
       "  0.01410122960805893,\n",
       "  0.013555246405303478,\n",
       "  0.013071177527308464,\n",
       "  0.012617276981472969,\n",
       "  0.012762017548084259,\n",
       "  0.011787133291363716]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load('model_checkpoint.pth')#load the model\n",
    "checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['epoch', 'model_state_dict', 'optimizer_state_dict', 'loss', 'val_loss'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('0.weight', tensor([[2.0392]], device='cuda:0')),\n",
       "             ('0.bias', tensor([9.7361], device='cuda:0'))])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint['model_state_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('0.weight', tensor([[2.0392]], device='cuda:0')),\n",
       "             ('0.bias', tensor([9.7361], device='cuda:0'))])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(checkpoint['model_state_dict']) #load model  state dictionaries back using load state dict \n",
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict']) #load optimizer state dict back using load state dict \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#laod every things into their corresponding values \n",
    "saved_epoch = checkpoint['epoch']\n",
    "saved_loss =checkpoint['loss'] \n",
    "saved_val_losses = checkpoint['val_loss']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## now resume tranning form this check-point using model.train()\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=1, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('0.weight', tensor([[2.0392]], device='cuda:0')),\n",
       "             ('0.bias', tensor([9.7361], device='cuda:0'))])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# up to here we have recover our model state and we can resume tranning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " #now we can run our model_traning v5 which n_epochs  is 200 ; thus , our model will now again train for 200 epochs more from curerct epochs\n",
    "current_epoch = saved_epoch\n",
    "current_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i model_training/v5.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('0.weight', tensor([[2.0012]], device='cuda:0')),\n",
       "             ('0.bias', tensor([9.9921], device='cuda:0'))])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the model we saved to disk was fully trainned model so we can use it for deploying / making prediction \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying / Making Prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i model_configuration/v3.py #once again we have untrain the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('0.weight', tensor([[2.0392]], device='cuda:0')),\n",
       "             ('0.bias', tensor([9.7361], device='cuda:0'))])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#recovering our model state \n",
    "\n",
    "checkpoint = torch.load('model_checkpoint.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "#since the mode is fully traned model to make prediction we dont need to load the optimizer or anything else \n",
    "model.state_dict() \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10.1439],\n",
       "        [10.4294],\n",
       "        [10.8984]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#making prediction in new inputs \n",
    "new_inputs = torch.tensor([[.20] , [.34] , [.57]])\n",
    "model.eval() #always use eval for fully trained models \n",
    "model(new_inputs.to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## important \n",
    "# After checkpointing : model.train()\n",
    "# after depolying/making_prediction : model.eval() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
