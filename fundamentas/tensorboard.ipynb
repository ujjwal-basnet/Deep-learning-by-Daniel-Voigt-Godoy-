{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full pipeline \n",
    "%run -i data_preparation/v2.py\n",
    "%run -i model_configuration/v2.py\n",
    "%run -i model_training/v4.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lunch tensorbard "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 5088), started 1 day, 5:55:19 ago. (Use '!kill 5088' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-ad4d27fe466928d\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-ad4d27fe466928d\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\ujjwal\\\\Deep-learning\\\\fundamentas'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('runs/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('0.weight', tensor([[2.0481]], device='cuda:0')),\n",
       "             ('0.bias', tensor([9.7007], device='cuda:0'))])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_x , dummy_y = next(iter(train_loader))\n",
    "dummy_x = dummy_x.view(-1,1)\n",
    "dumym_y  = dummy_y.view(-1 , 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_graph(model , dummy_x.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_scalars(\n",
    "  main_tag='loss',\n",
    "  tag_scalar_dict={'training': loss,\n",
    "                    'validation': val_loss},\n",
    "  global_step= epcoh)\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 5088), started 1 day, 5:55:27 ago. (Use '!kill 5088' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-f3da724f11c53f7c\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-f3da724f11c53f7c\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i data_preparation/v2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load model_configuration/v2.py\n",
    "import torch \n",
    "import torch.optim as optim \n",
    "import torch.nn as nn \n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "lr = 0.01 #set learning rate \n",
    "model = nn.Sequential(nn.Linear(1,1).to(device))\n",
    "optimizer = optim.SGD(model.parameters() , lr = lr)\n",
    "loss_fn = nn.MSELoss(reduction= 'mean')\n",
    "\n",
    "\n",
    "def make_train_step_fn(model , loss_fn , optimizer):\n",
    "    def train_step(x ,y):\n",
    "        model.train()\n",
    "        yhat = model(x)\n",
    "        loss = loss_fn(yhat , y)\n",
    "        loss.backward() #calcualte gradients \n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        return loss.item()\n",
    "    return train_step\n",
    "\n",
    "train_step_fn = make_train_step_fn(model , loss_fn , optimizer)\n",
    "\n",
    "def make_val_step_fn(model , loss_fn):\n",
    "    def perform_val_step(x ,y ):\n",
    "        model.eval() #model evaluation \n",
    "        yhat = model(x)\n",
    "        loss = loss_fn(yhat , y)\n",
    "        return loss.item()\n",
    "    return perform_val_step\n",
    "\n",
    "\n",
    "val_step_fn = make_val_step_fn(model , loss_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model_configuration/v3.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model_configuration/v3.py\n",
    "import torch \n",
    "import torch.optim as optim \n",
    "import torch.nn as nn \n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "import torch.optim as optim\n",
    "\n",
    "def make_train_step_fn(model , optimizer , loss_fn):\n",
    "    def train_step(x ,y ):\n",
    "        model.train() \n",
    "        yhat = model(x)\n",
    "        loss = loss_fn(yhat , y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        return loss.item()\n",
    "    \n",
    "    return train_step \n",
    "\n",
    "def make_val_step_fn(model , loss_fn):\n",
    "    def perform_val_step(x ,y ):\n",
    "        model.eval()\n",
    "        yhat = model(x)\n",
    "        loss = loss_fn(yhat , y)\n",
    "        return loss.item()\n",
    "    return perform_val_step\n",
    "        \n",
    "\n",
    "#set lr rate \n",
    "lr = 0.01\n",
    "torch.manual_seed(42)\n",
    "model = nn.Sequential(nn.Linear(1 ,1 ).to(device))\n",
    "optimizer = optim.SGD(model.parameters() , lr = lr)\n",
    "loss_fn = nn.MSELoss(reduction = 'mean')\n",
    "\n",
    "train_step_fn = make_train_step_fn(model , loss_fn , optimizer)\n",
    "val_step_fn = make_val_step_fn(model , loss_fn)\n",
    "\n",
    "#create a summary writter to interface with tensorboard \n",
    "writer = SummaryWriter('runs/simple_linear_regression')\n",
    "#fetch single mini batch so we can use add_graph\n",
    "x_dummy , y_dummy = next(iter(train_loader))\n",
    "x_dummy = x_dummy.view(-1 , 1)\n",
    "y_dummy = y_dummy.view(-1,1)\n",
    "writer.add_graph(model , x_dummy.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i model_configuration/v3.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 5.0000],\n",
       "         [ 2.0000],\n",
       "         [ 4.9091],\n",
       "         [ 4.0000],\n",
       "         [ 4.0909],\n",
       "         [ 4.6364],\n",
       "         [ 8.0909],\n",
       "         [ 1.4545],\n",
       "         [ 9.5455],\n",
       "         [ 6.2727],\n",
       "         [10.0000],\n",
       "         [ 6.4545],\n",
       "         [ 5.5455],\n",
       "         [ 8.9091],\n",
       "         [ 5.1818],\n",
       "         [ 1.2727]]),\n",
       " tensor([[20.0000],\n",
       "         [14.0000],\n",
       "         [19.8182],\n",
       "         [18.0000],\n",
       "         [18.1818],\n",
       "         [19.2727],\n",
       "         [26.1818],\n",
       "         [12.9091],\n",
       "         [29.0909],\n",
       "         [22.5455],\n",
       "         [30.0000],\n",
       "         [22.9091],\n",
       "         [21.0909],\n",
       "         [27.8182],\n",
       "         [20.3636],\n",
       "         [12.5455]])]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[4.8182],\n",
       "         [4.2727],\n",
       "         [7.2727],\n",
       "         [4.6364],\n",
       "         [1.8182],\n",
       "         [6.5455],\n",
       "         [9.6364],\n",
       "         [8.8182],\n",
       "         [7.0909],\n",
       "         [6.9091],\n",
       "         [1.2727],\n",
       "         [9.5455],\n",
       "         [4.3636],\n",
       "         [9.0000],\n",
       "         [5.6364],\n",
       "         [9.7273]]),\n",
       " tensor([[19.6364],\n",
       "         [18.5455],\n",
       "         [24.5455],\n",
       "         [19.2727],\n",
       "         [13.6364],\n",
       "         [23.0909],\n",
       "         [29.2727],\n",
       "         [27.6364],\n",
       "         [24.1818],\n",
       "         [23.8182],\n",
       "         [12.5455],\n",
       "         [29.0909],\n",
       "         [18.7273],\n",
       "         [28.0000],\n",
       "         [21.2727],\n",
       "         [29.4545]])]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%run -i data_preparation/v2.py \n",
    "%run -i model_configuration/v3.py\n",
    "%run -i model_training/v3.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing model_training/v5.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model_training/v5.py\n",
    "import numpy  as np \n",
    "def mini_batch(device , train_loader , train_step_fn):\n",
    "    mini_batch_losses = []\n",
    "    for x_batch , y_batch in train_loader:\n",
    "        x_batch = x_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        mini_batch_loss = train_step_fn(x_batch , y_batch)\n",
    "        mini_batch_losses.append(mini_batch_loss)\n",
    "\n",
    "    loss = np.mean(mini_batch_loss)\n",
    "    return loss \n",
    "\n",
    "        \n",
    "\n",
    "n_epcohs = 200 \n",
    "losses = []\n",
    "val_losses = [] \n",
    "for epcoh in range(n_epcohs):\n",
    "    #inner loop \n",
    "    loss = mini_batch(device ,  train_loader , train_step_fn)\n",
    "    losses.append(loss)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        val_loss = mini_batch(device , val_loader , val_step_fn)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "    writer.add_scalars(main_tag = 'loss' , \n",
    "                      tag_scalar_dict  = {'tranning': loss , \n",
    "                                         'validation': val_loss} , \n",
    "                      global_step = epcoh)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i model_training/v5.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('0.weight', tensor([[2.0000]], device='cuda:0')),\n",
       "             ('0.bias', tensor([9.9998], device='cuda:0'))])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 5088), started 1 day, 6:31:08 ago. (Use '!kill 5088' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-e0c62473973cdc51\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-e0c62473973cdc51\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir runs/test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save the checkpoint \n",
    "Training a model successfully is great, no doubt about that, but not all models will\n",
    "train quickly, and training may get interrupted (computer crashing, timeout after\n",
    "12 hours of continuous GPU usage on Google Colab, etc.). It would be a pity to have\n",
    "to start over, right?\n",
    "So, it is important to be able to checkpoint or save our model, that is, save it to disk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('0.weight', tensor([[2.0000]], device='cuda:0')),\n",
       "             ('0.bias', tensor([9.9998], device='cuda:0'))])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fror checkpoint we basically have to state to a file so that it can be loaded later \n",
    "#save \n",
    "checkpoint = {'epoch': n_epochs,\n",
    "  'model_state_dict': model.state_dict(),\n",
    "  'optimizer_state_dict': optimizer.state_dict(),\n",
    "  'loss': losses,\n",
    "  'val_loss': val_losses}\n",
    "torch.save(checkpoint, 'model_checkpoint.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Failed to launch TensorBoard (exited with 2).\n",
       "Contents of stderr:\n",
       "TensorFlow installation not found - running with reduced feature set.\n",
       "usage: tensorboard [-h] [--helpfull] {serve} ...\n",
       "tensorboard: error: argument {serve}: invalid choice: 'logdirs' (choose from 'serve')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard logdirs --runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Writer will output to ./runs/ directory by default\n",
    "writer = SummaryWriter('run/test22')\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "trainset = datasets.MNIST('mnist_train', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "model = torchvision.models.resnet50(False)\n",
    "# Have ResNet model take in grayscale rather than RGB\n",
    "model.conv1 = torch.nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "images, labels = next(iter(trainloader))\n",
    "\n",
    "grid = torchvision.utils.make_grid(images)\n",
    "writer.add_image('images', grid, 0)\n",
    "writer.add_graph(model, images)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Failed to launch TensorBoard (exited with 2).\n",
       "Contents of stderr:\n",
       "TensorFlow installation not found - running with reduced feature set.\n",
       "usage: tensorboard [-h] [--helpfull] [--logdir PATH] [--logdir_spec PATH_SPEC]\n",
       "                   [--host ADDR] [--bind_all] [--port PORT]\n",
       "                   [--reuse_port BOOL] [--load_fast {false,auto,true}]\n",
       "                   [--extra_data_server_flags EXTRA_DATA_SERVER_FLAGS]\n",
       "                   [--grpc_creds_type {local,ssl,ssl_dev}]\n",
       "                   [--grpc_data_provider PORT] [--purge_orphaned_data BOOL]\n",
       "                   [--db URI] [--db_import] [--inspect] [--version_tb]\n",
       "                   [--tag TAG] [--event_file PATH] [--path_prefix PATH]\n",
       "                   [--window_title TEXT] [--max_reload_threads COUNT]\n",
       "                   [--reload_interval SECONDS] [--reload_task TYPE]\n",
       "                   [--reload_multifile BOOL]\n",
       "                   [--reload_multifile_inactive_secs SECONDS]\n",
       "                   [--generic_data TYPE]\n",
       "                   [--samples_per_plugin SAMPLES_PER_PLUGIN]\n",
       "                   [--detect_file_replacement BOOL]\n",
       "                   {serve} ...\n",
       "tensorboard: error: argument {serve}: invalid choice: 'run' (choose from 'serve')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "\n",
    "writer = SummaryWriter()\n",
    "\n",
    "for n_iter in range(100):\n",
    "    writer.add_scalar('Loss/train', np.random.random(), n_iter)\n",
    "    writer.add_scalar('Loss/test', np.random.random(), n_iter)\n",
    "    writer.add_scalar('Accuracy/train', np.random.random(), n_iter)\n",
    "    writer.add_scalar('Accuracy/test', np.random.random(), n_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdirs run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ended "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_graph(model , dummy_x.tp(device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('runs/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected 3D (unbatched) or 4D (batched) input to conv2d, but got input of size: [16, 1]\n",
      "Error occurs, No graph saved\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected 3D (unbatched) or 4D (batched) input to conv2d, but got input of size: [16, 1]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mwriter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdummy_x\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\software\\miniconda\\envs\\mlenv\\Lib\\site-packages\\torch\\utils\\tensorboard\\writer.py:889\u001b[0m, in \u001b[0;36mSummaryWriter.add_graph\u001b[1;34m(self, model, input_to_model, verbose, use_strict_trace)\u001b[0m\n\u001b[0;32m    885\u001b[0m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_log_api_usage_once(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensorboard.logging.add_graph\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    886\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    887\u001b[0m     \u001b[38;5;66;03m# A valid PyTorch model should have a 'forward' method\u001b[39;00m\n\u001b[0;32m    888\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_file_writer()\u001b[38;5;241m.\u001b[39madd_graph(\n\u001b[1;32m--> 889\u001b[0m         \u001b[43mgraph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_to_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_strict_trace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    890\u001b[0m     )\n\u001b[0;32m    891\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    892\u001b[0m     \u001b[38;5;66;03m# Caffe2 models do not have the 'forward' method\u001b[39;00m\n\u001b[0;32m    893\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcaffe2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mproto\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m caffe2_pb2\n",
      "File \u001b[1;32md:\\software\\miniconda\\envs\\mlenv\\Lib\\site-packages\\torch\\utils\\tensorboard\\_pytorch_graph.py:336\u001b[0m, in \u001b[0;36mgraph\u001b[1;34m(model, args, verbose, use_strict_trace)\u001b[0m\n\u001b[0;32m    334\u001b[0m         \u001b[38;5;28mprint\u001b[39m(e)\n\u001b[0;32m    335\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError occurs, No graph saved\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 336\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    338\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[0;32m    339\u001b[0m     \u001b[38;5;28mprint\u001b[39m(graph)\n",
      "File \u001b[1;32md:\\software\\miniconda\\envs\\mlenv\\Lib\\site-packages\\torch\\utils\\tensorboard\\_pytorch_graph.py:330\u001b[0m, in \u001b[0;36mgraph\u001b[1;34m(model, args, verbose, use_strict_trace)\u001b[0m\n\u001b[0;32m    328\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _set_model_to_eval(model):\n\u001b[0;32m    329\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 330\u001b[0m         trace \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_strict_trace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    331\u001b[0m         graph \u001b[38;5;241m=\u001b[39m trace\u001b[38;5;241m.\u001b[39mgraph\n\u001b[0;32m    332\u001b[0m         torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_jit_pass_inline(graph)\n",
      "File \u001b[1;32md:\\software\\miniconda\\envs\\mlenv\\Lib\\site-packages\\torch\\jit\\_trace.py:820\u001b[0m, in \u001b[0;36mtrace\u001b[1;34m(func, example_inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit, example_kwarg_inputs, _store_inputs)\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    819\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexample_kwarg_inputs should be a dict\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 820\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrace_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    821\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    822\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforward\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    823\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_trace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwrap_check_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheck_inputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_tolerance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    827\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    828\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_force_outplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    829\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_module_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexample_inputs_is_kwarg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mexample_kwarg_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_store_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_store_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    832\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    833\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    834\u001b[0m     \u001b[38;5;28mhasattr\u001b[39m(func, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__self__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    835\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m, torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule)\n\u001b[0;32m    836\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    837\u001b[0m ):\n\u001b[0;32m    838\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m example_inputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32md:\\software\\miniconda\\envs\\mlenv\\Lib\\site-packages\\torch\\jit\\_trace.py:1088\u001b[0m, in \u001b[0;36mtrace_module\u001b[1;34m(mod, inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit, example_inputs_is_kwarg, _store_inputs)\u001b[0m\n\u001b[0;32m   1086\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1087\u001b[0m     example_inputs \u001b[38;5;241m=\u001b[39m make_tuple(example_inputs)\n\u001b[1;32m-> 1088\u001b[0m     \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_c\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_method_from_trace\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1089\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1090\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1091\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1092\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvar_lookup_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1093\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1094\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_force_outplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1095\u001b[0m \u001b[43m        \u001b[49m\u001b[43margument_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1096\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_store_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1097\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1099\u001b[0m check_trace_method \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_c\u001b[38;5;241m.\u001b[39m_get_method(method_name)\n\u001b[0;32m   1101\u001b[0m \u001b[38;5;66;03m# Check the trace against new traces created from user-specified inputs\u001b[39;00m\n",
      "File \u001b[1;32md:\\software\\miniconda\\envs\\mlenv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\software\\miniconda\\envs\\mlenv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\software\\miniconda\\envs\\mlenv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1522\u001b[0m, in \u001b[0;36mModule._slow_forward\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1520\u001b[0m         recording_scopes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1521\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1522\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1524\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m recording_scopes:\n",
      "File \u001b[1;32md:\\software\\miniconda\\envs\\mlenv\\Lib\\site-packages\\torchvision\\models\\resnet.py:285\u001b[0m, in \u001b[0;36mResNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\software\\miniconda\\envs\\mlenv\\Lib\\site-packages\\torchvision\\models\\resnet.py:268\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_forward_impl\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m    267\u001b[0m     \u001b[38;5;66;03m# See note [TorchScript super()]\u001b[39;00m\n\u001b[1;32m--> 268\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    269\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(x)\n\u001b[0;32m    270\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(x)\n",
      "File \u001b[1;32md:\\software\\miniconda\\envs\\mlenv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\software\\miniconda\\envs\\mlenv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\software\\miniconda\\envs\\mlenv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1522\u001b[0m, in \u001b[0;36mModule._slow_forward\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1520\u001b[0m         recording_scopes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1521\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1522\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1524\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m recording_scopes:\n",
      "File \u001b[1;32md:\\software\\miniconda\\envs\\mlenv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\software\\miniconda\\envs\\mlenv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected 3D (unbatched) or 4D (batched) input to conv2d, but got input of size: [16, 1]"
     ]
    }
   ],
   "source": [
    "writer.add_graph(model , dummy_x.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
