{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\software\\miniconda\\envs\\mlenv\\Lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] The specified procedure could not be found'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.transforms import Compose, Normalize\n",
    "from image_classification import generate_dataset\n",
    "from helpers import index_splitter, make_balanced_sampler\n",
    "from v1 import StepByStep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 6, 6)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single = np.array(\n",
    "  [[[[5, 0, 8, 7, 8, 1],\n",
    "  [1, 9, 5, 0, 7, 7],\n",
    "  [6, 0, 2, 4, 6, 6],\n",
    "  [9, 7, 6, 6, 8, 4],\n",
    "  [8, 3, 8, 5, 1, 3],\n",
    "  [7, 2, 7, 0, 1, 0]]]]\n",
    ")\n",
    "single.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 3, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "identity = np.array(\n",
    "  [[[[0, 0, 0],\n",
    "  [0, 1, 0],\n",
    "  [0, 0, 0]]]]\n",
    ")\n",
    "identity.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## convolvign\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[5, 0, 8, 7, 8, 1],\n",
       "         [1, 9, 5, 0, 7, 7],\n",
       "         [6, 0, 2, 4, 6, 6],\n",
       "         [9, 7, 6, 6, 8, 4],\n",
       "         [8, 3, 8, 5, 1, 3],\n",
       "         [7, 2, 7, 0, 1, 0]]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 6, 6)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 0, 8],\n",
       "       [1, 9, 5],\n",
       "       [6, 0, 2]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single[0,0 , 0:3 , 0:3 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0, 0, 0],\n",
       "         [0, 9, 0],\n",
       "         [0, 0, 0]]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#element viase multiplication\n",
    "region = single[0 , 0 , 0: 3  , 0:3] \n",
    "multiplication = region * identity\n",
    "multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0, 0, 0],\n",
       "         [0, 9, 0],\n",
       "         [0, 0, 0]]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "region @ identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#total is \n",
    "multiplication.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9, 5, 0],\n",
       "       [0, 2, 4],\n",
       "       [7, 6, 6]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newregion = single[0, 0, (0+1):(3+1) , (0+1):(3+1)]\n",
    "newregion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[5, 0, 8, 7, 8, 1],\n",
       "         [1, 9, 5, 0, 7, 7],\n",
       "         [6, 0, 2, 4, 6, 6],\n",
       "         [9, 7, 6, 6, 8, 4],\n",
       "         [8, 3, 8, 5, 1, 3],\n",
       "         [7, 2, 7, 0, 1, 0]]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans = []\n",
    "single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0, 0, 0],\n",
       "         [0, 1, 0],\n",
       "         [0, 0, 0]]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def helper(single , filter):\n",
    "    row_S = single.shape[2]\n",
    "    column_S= single.shape[3]\n",
    "\n",
    "    row_F , column_F  = filter.shape[2] , filter.shape[3]\n",
    "    row_move = row_S - row_F\n",
    "    col_move= column_S - column_F\n",
    "\n",
    "    return row_move, col_move \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = []\n",
    "row_move, column_move = helper(single , identity)\n",
    "#initilized ans \n",
    "ans = np.zeros((1,1,4 , 4))\n",
    "\n",
    "for i in range(row_move + 1):\n",
    "    for j in range(column_move + 1):\n",
    "                    \n",
    "            res = single[0, 0, (0+i):(3+i), (0+j):(3+j)]\n",
    "            matrix = res * identity\n",
    "            ans[0 , 0 , i , j]=  matrix.sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = torch.as_tensor(single).float()\n",
    "kernal_identity = torch.as_tensor(identity).float()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### he functional convolution takes the kernel / \n",
    "#### filter as an argument\n",
    "#### while the module has (learnable) weights to\n",
    "#### represent the kernel / filter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[9., 5., 0., 7.],\n",
       "          [0., 2., 4., 6.],\n",
       "          [7., 6., 6., 8.],\n",
       "          [3., 8., 5., 1.]]]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using functional convolution \n",
    "convolved = F.conv2d(input= image, weight = kernal_identity, stride= 1 )\n",
    "convolved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[9., 0.],\n",
       "          [7., 6.]]]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convolved = F.conv2d(input = image , weight = kernal_identity , stride = 2)\n",
    "convolved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 1.4746e+00,  3.3917e+00, -4.9142e-01,  4.7803e-01],\n",
       "          [ 2.0855e+00, -1.9216e-03, -1.2186e-01,  2.1849e+00],\n",
       "          [ 9.6041e-01,  1.5007e+00,  1.6795e+00,  2.5719e+00],\n",
       "          [ 1.7517e-01,  2.6866e+00,  3.4533e+00,  1.1268e+00]]]],\n",
       "       grad_fn=<ConvolutionBackward0>)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv = nn.Conv2d(in_channels= 1, out_channels= 1, kernel_size= 3, stride= 1)\n",
    "conv(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## result are gibberish  now because, convolution module randomly initilizes the weights representing the kernal/filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That’s the whole point of the convolutional module: It will learn\n",
    "the kernel / filter on its own.<br>\n",
    "In traditional computer vision, people would develop different<br>\n",
    "filters for different purposes: blurring, sharpening, edge<br>\n",
    "detection, and so on.<br><br><br>\n",
    "But, instead of being clever and trying to manually devise a filter<br>\n",
    "that does the trick for a given problem, why not outsource the<br>\n",
    "filter definition to the neural network as well? This way, the<br>\n",
    "network will come up with filters that highlight features that are<br>\n",
    "relevant to the task at hand.<br><br><br>\n",
    "It’s no surprise that the resulting image shows a grad_fn attribute<br>\n",
    "now: It will be used to compute gradients so the network can<br>\n",
    "actually learn how to change the weights representing the filter.<str>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"Can we tell it to learn multiple filters at once?\"\n",
    "## Sure we can; that’s the role of the out_channels argument. If we set it to 2, \n",
    "### it will generate two (randomly initialized) filters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-2.0121, -3.6809, -5.8810, -6.8342],\n",
       "          [-8.4024, -8.0421, -5.7923, -5.6644],\n",
       "          [-8.8336, -5.7163, -5.5102, -4.7129],\n",
       "          [-8.6719, -4.4343, -5.2004, -3.2441]],\n",
       "\n",
       "         [[ 2.5142,  4.5170,  4.6755,  4.0351],\n",
       "          [ 5.8265,  3.9043,  4.4481,  4.9945],\n",
       "          [ 4.6511,  4.2423,  3.8007,  3.9694],\n",
       "          [ 5.3306,  3.8923,  4.3593,  2.5462]]]],\n",
       "       grad_fn=<ConvolutionBackward0>)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_multiple = nn.Conv2d(in_channels= 1, out_channels=2, kernel_size= 3, stride=1)\n",
    "conv_multiple(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Even if you have only one channel as input, you can have many channels as output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -- forcing convolution module to use particular filter by setting --#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0159,  0.1001,  0.0744],\n",
       "         [ 0.1343,  0.2389, -0.2990],\n",
       "         [ 0.0747,  0.1119, -0.1390]]])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.weight[0].data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0159,  0.1001,  0.0744],\n",
       "         [ 0.1343,  0.2389, -0.2990],\n",
       "         [ 0.0747,  0.1119, -0.1390]]])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.weight[0].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[5., 0., 8., 7., 8., 1.],\n",
       "          [1., 9., 5., 0., 7., 7.],\n",
       "          [6., 0., 2., 4., 6., 6.],\n",
       "          [9., 7., 6., 6., 8., 4.],\n",
       "          [8., 3., 8., 5., 1., 3.],\n",
       "          [7., 2., 7., 0., 1., 0.]]]])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernal_identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using boring identity kernal\n",
    "conv = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=3, stride=1, padding=0)\n",
    "\n",
    "# Set the kernel and bias using torch.no_grad() to prevent gradient calculation\n",
    "with torch.no_grad():\n",
    "    conv.weight[0] = kernal_identity  # Correctly assigning the kernel weights\n",
    "    conv.bias[0] = 0   # Correctly assigning the bias to 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[9., 5., 0., 7.],\n",
       "          [0., 2., 4., 6.],\n",
       "          [7., 6., 6., 8.],\n",
       "          [3., 8., 5., 1.]]]], grad_fn=<ConvolutionBackward0>)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "constant_padder = nn.ConstantPad2d(padding = 1 , value = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 5., 0., 8., 7., 8., 1., 0.],\n",
       "          [0., 1., 9., 5., 0., 7., 7., 0.],\n",
       "          [0., 6., 0., 2., 4., 6., 6., 0.],\n",
       "          [0., 9., 7., 6., 6., 8., 4., 0.],\n",
       "          [0., 8., 3., 8., 5., 1., 3., 0.],\n",
       "          [0., 7., 2., 7., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0.]]]])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "constant_padder(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Padding Documentation\n",
    "\n",
    "This document provides details on how to use the padding arguments for image manipulation functions. Padding is used to add extra space around the edges of an image.\n",
    "\n",
    "## Arguments\n",
    "\n",
    "### `padding`\n",
    "\n",
    "The `padding` argument specifies the number of columns and rows to be added around the image. It can be provided in two formats:\n",
    "\n",
    "- **Integer**: Applies the same padding value to all sides of the image.\n",
    "  \n",
    "  - **Example**: `padding=2` adds 2 rows and 2 columns of padding to all sides (top, bottom, left, right).\n",
    "\n",
    "- **Tuple**: Applies different padding values to each side of the image. The tuple is specified as `(left, right, top, bottom)`.\n",
    "\n",
    "  - **Example**: `padding=(1, 1, 0, 0)` adds 1 column of padding to the left and right sides of the image, with no padding on the top and bottom.\n",
    "\n",
    "### `value`\n",
    "\n",
    "The `value` argument specifies the value that fills the newly added columns and rows. It can be any scalar value that the padding cells will be initialized with.\n",
    "\n",
    "## Examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "padder1 = nn.ConstantPad2d(padding = (1,1,0,0) , value = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., 5., 0., 8., 7., 8., 1., 0.],\n",
       "          [0., 1., 9., 5., 0., 7., 7., 0.],\n",
       "          [0., 6., 0., 2., 4., 6., 6., 0.],\n",
       "          [0., 9., 7., 6., 6., 8., 4., 0.],\n",
       "          [0., 8., 3., 8., 5., 1., 3., 0.],\n",
       "          [0., 7., 2., 7., 0., 1., 0., 0.]]]])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padder1(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 5., 0., 8., 7., 8., 1., 0.],\n",
       "          [0., 1., 9., 5., 0., 7., 7., 0.],\n",
       "          [0., 6., 0., 2., 4., 6., 6., 0.],\n",
       "          [0., 9., 7., 6., 6., 8., 4., 0.],\n",
       "          [0., 8., 3., 8., 5., 1., 3., 0.],\n",
       "          [0., 7., 2., 7., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0.]]]])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded = F.pad(input = image, pad=(1,1,1,1), mode= 'constant', value=0)\n",
    "padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
