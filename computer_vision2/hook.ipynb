{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a= torch.tensor(2.0, requires_grad= False)\n",
    "b= torch.tensor(3.0, requires_grad= False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## both a and b grad is false then  c grad will also be false so no grad calcialte\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For a \n",
      "data = 2.0\n",
      "grad = None\n",
      "is_leaf= True\n",
      "requires_grad= False\n",
      "\n",
      "\n",
      "\n",
      "For b \n",
      "data = 3.0\n",
      "grad = None\n",
      "is_leaf= True\n",
      "requires_grad= False\n"
     ]
    }
   ],
   "source": [
    "print(\"For a \")\n",
    "print(f'data = {a.data}')\n",
    "print(f'grad = {a.grad}')\n",
    "print(f'is_leaf= {a.is_leaf}')\n",
    "print(f'requires_grad= {a.requires_grad}')\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "print(\"For b \")\n",
    "print(f'data = {b.data}')\n",
    "print(f'grad = {b.grad}')\n",
    "print(f'is_leaf= {b.is_leaf}')\n",
    "print(f'requires_grad= {b.requires_grad}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For c \n",
      "data = 6.0\n",
      "grad = None\n",
      "is_leaf= True\n",
      "requires_grad= False\n"
     ]
    }
   ],
   "source": [
    "c = a * b \n",
    "\n",
    "print(\"For c \")\n",
    "print(f'data = {c.data}')\n",
    "print(f'grad = {c.grad}')\n",
    "print(f'is_leaf= {c.is_leaf}')\n",
    "print(f'requires_grad= {c.requires_grad}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##if one grad is True then ouput grad will also be true "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For a \n",
      "data = 2.0\n",
      "grad = None\n",
      "is_leaf= True\n",
      "requires_grad= False\n",
      "\n",
      "\n",
      "\n",
      "For b \n",
      "data = 3.0\n",
      "grad = None\n",
      "is_leaf= True\n",
      "requires_grad= False\n",
      "For c \n",
      "data = 6.0\n",
      "grad = None\n",
      "is_leaf= True\n",
      "requires_grad= False\n"
     ]
    }
   ],
   "source": [
    "a= torch.tensor(2.0, requires_grad= False)\n",
    "b= torch.tensor(3.0, requires_grad= False)\n",
    "\n",
    "\n",
    "print(\"For a \")\n",
    "print(f'data = {a.data}')\n",
    "print(f'grad = {a.grad}')\n",
    "print(f'is_leaf= {a.is_leaf}')\n",
    "print(f'requires_grad= {a.requires_grad}')\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "print(\"For b \")\n",
    "print(f'data = {b.data}')\n",
    "print(f'grad = {b.grad}')\n",
    "print(f'is_leaf= {b.is_leaf}')\n",
    "print(f'requires_grad= {b.requires_grad}')\n",
    "\n",
    "\n",
    "c = a * b \n",
    "\n",
    "print(\"For c \")\n",
    "print(f'data = {c.data}')\n",
    "print(f'grad = {c.grad}')\n",
    "print(f'is_leaf= {c.is_leaf}')\n",
    "print(f'requires_grad= {c.requires_grad}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## grad "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for c: tensor(1.)\n",
      "Gradient of a: tensor(9.)\n",
      "Gradient of b: tensor(6.)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Define tensors with requires_grad=True\n",
    "a = torch.tensor(2.0, requires_grad=True)\n",
    "b = torch.tensor(3.0, requires_grad=True)\n",
    "\n",
    "# Define the computation\n",
    "c = a * b\n",
    "\n",
    "# Define a hook to print gradients (although in this case it's more relevant to show the result directly)\n",
    "def c_hook(grad):\n",
    "    print(\"Gradient for c:\", grad)\n",
    "    return grad + 2  # Just for demonstration; normally you'd return the gradient as-is\n",
    "\n",
    "# Register the hook on tensor c\n",
    "c.register_hook(c_hook)\n",
    "\n",
    "# Perform backward pass to compute gradients\n",
    "c.backward()\n",
    "\n",
    "# Print gradients for tensors a and b\n",
    "print(\"Gradient of a:\", a.grad)\n",
    "print(\"Gradient of b:\", b.grad)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## unnecessary usages of the grad \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for a:  tensor(100.)\n",
      "Gradient for b: tensor(100.)\n",
      "Gradien d: tensor(100.)\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor(2., requires_grad= True).float()\n",
    "b= torch.tensor(3., requires_grad= True).float()\n",
    "\n",
    "#define the computation\n",
    "c = a + b\n",
    "\n",
    "d = torch.tensor(4., requires_grad= True).float()\n",
    "def d_hook(grad):\n",
    "    grad *= 100 \n",
    "\n",
    "d.register_hook(d_hook)\n",
    "e= c + d \n",
    "e.backward()\n",
    "\n",
    "print('Gradient for a: ',a.grad)\n",
    "print('Gradient for b:' , b.grad)\n",
    "print('Gradien d:', d.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10., grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 4",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 58\u001b[0m\n\u001b[0;32m     56\u001b[0m x_train_tensor \u001b[38;5;241m=\u001b[39m x_tensor[train_idx]\n\u001b[0;32m     57\u001b[0m y_train_tensor \u001b[38;5;241m=\u001b[39m y_tensor[train_idx]\n\u001b[1;32m---> 58\u001b[0m x_val_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mx_tensor\u001b[49m\u001b[43m[\u001b[49m\u001b[43mval_idx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     59\u001b[0m y_val_tensor \u001b[38;5;241m=\u001b[39m y_tensor[val_idx]\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# We're not doing any data augmentation now\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for tensor of dimension 4"
     ]
    }
   ],
   "source": [
    "\n",
    "# Common Libraries\n",
    "import random \n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Image Augmentation \n",
    "from PIL import Image \n",
    "from image_classification import generate_dataset \n",
    "\n",
    "# Previously Defined Functions and Classes\n",
    "from v1 import StepByStep \n",
    "from torch.utils.data import Dataset , DataLoader\n",
    "\n",
    "# Data Utilities\n",
    "from helpers import index_splitter, make_balanced_sampler\n",
    "from torchvision.transforms import Compose,Normalize\n",
    "\n",
    "#PyTorch Optimization and Loss Functions\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "#data geneartion \n",
    "\n",
    "\n",
    "images, labels= generate_dataset(img_size=10, n_images=100, binary=False, seed=17)\n",
    "\n",
    "############## data preparation ######################### \n",
    "class TransformedTensorDataset(Dataset):\n",
    "    def __init__(self, x, y, transformed=None):\n",
    "        self.x = x\n",
    "        self.y= y\n",
    "        self.transfomed= transformed \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x= self.x[index]\n",
    "        if self.transfomed:\n",
    "            x=self.transfomed(x)\n",
    "        return x, self.y[index] \n",
    "\n",
    "    def __len__(self, x):\n",
    "        return len(self.x)\n",
    "    \n",
    "\n",
    "############# data preparation 2 #######################\n",
    "# Builds tensors from numpy arrays BEFORE split\n",
    "# Modifies the scale of pixel values from [0, 255] to [0, 1]\n",
    "x_tensor = torch.as_tensor(images / 255).float()\n",
    "y_tensor = torch.as_tensor(labels).long()\n",
    "\n",
    "# Uses index_splitter to generate indices for training and\n",
    "# validation sets\n",
    "train_idx, val_idx = index_splitter(len(x_tensor), [80, 20])\n",
    "# Uses indices to perform the split\n",
    "x_train_tensor = x_tensor[train_idx]\n",
    "y_train_tensor = y_tensor[train_idx]\n",
    "x_val_tensor = x_tensor[val_idx]\n",
    "y_val_tensor = y_tensor[val_idx]\n",
    "\n",
    "# We're not doing any data augmentation now\n",
    "train_composer = Compose([Normalize(mean=(.5,), std=(.5,))])\n",
    "val_composer = Compose([Normalize(mean=(.5,), std=(.5,))])\n",
    "\n",
    "# Uses custom dataset to apply composed transforms to each set\n",
    "train_dataset = TransformedTensorDataset(x_train_tensor, y_train_tensor, transform=train_composer)\n",
    "val_dataset = TransformedTensorDataset(x_val_tensor, y_val_tensor, transform=val_composer)\n",
    "\n",
    "# Builds a weighted random sampler to handle imbalanced classes\n",
    "sampler = make_balanced_sampler(y_train_tensor)\n",
    "\n",
    "# Uses sampler in the training set to get a balanced data loader\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=16, sampler=sampler)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=16)\n",
    "####################### model configuration ##########################################################\n",
    "\n",
    "torch.manual_seed(42)\n",
    "model_cnn1= nn.Sequential()\n",
    "\n",
    "n_channels= 1 \n",
    "model_cnn1.add_module('conv1', nn.Conv2d(in_channels=1, out_channels=n_channels, kernel_size=3))\n",
    "model_cnn1.add_module('relu1',nn.ReLU())\n",
    "model_cnn1.add_module('maxp1', nn.MaxPool2d(kernel_size=2))\n",
    "#flattening : n channles *4 *4 \n",
    "\n",
    "model_cnn1.add_module('flattern', nn.Flatten())\n",
    "\n",
    "#clasification  #hidden layer\n",
    "model_cnn1.add_module('fc1',  nn.Linear(in_features=n_channels*4*4, out_features= 10))\n",
    "model_cnn1.add_module('relu2', nn.ReLU())\n",
    "\n",
    "#output layer\n",
    "model_cnn1.add_module('fc2', nn.Linear(in_features=10, out_features=3))\n",
    "\n",
    "\n",
    "############ others parameters\n",
    "lr= 0.3\n",
    "multi_loss_fn= nn.CrossEntropyLoss(reducation='mean')\n",
    "optimizer_cnn1= optim.SGD(model_cnn1.parameters(),lr=lr)\n",
    "\n",
    "\n",
    "\n",
    "################# model training #########################\n",
    "sbs_cnn1 = StepByStep(model_cnn1, multi_loss_fn, lr=lr)\n",
    "sbs_cnn1.set_loaders(train_loader, val_loader) \n",
    "\n",
    "sbs_cnn1.train(20)\n",
    "\n",
    "fig= sbs_cnn1.plot_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 4",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m x_train_tensor \u001b[38;5;241m=\u001b[39m x_tensor[train_idx]\n\u001b[0;32m     11\u001b[0m y_train_tensor \u001b[38;5;241m=\u001b[39m y_tensor[train_idx]\n\u001b[1;32m---> 12\u001b[0m x_val_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mx_tensor\u001b[49m\u001b[43m[\u001b[49m\u001b[43mval_idx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     13\u001b[0m y_val_tensor \u001b[38;5;241m=\u001b[39m y_tensor[val_idx]\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# We're not doing any data augmentation now\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for tensor of dimension 4"
     ]
    }
   ],
   "source": [
    "# Builds tensors from numpy arrays BEFORE split\n",
    "# Modifies the scale of pixel values from [0, 255] to [0, 1]\n",
    "x_tensor = torch.as_tensor(images / 255).float()\n",
    "y_tensor = torch.as_tensor(labels).long()\n",
    "\n",
    "# Uses index_splitter to generate indices for training and\n",
    "# validation sets\n",
    "train_idx, val_idx = index_splitter(len(x_tensor), [80, 20])\n",
    "# Uses indices to perform the split\n",
    "x_train_tensor = x_tensor[train_idx]\n",
    "y_train_tensor = y_tensor[train_idx]\n",
    "x_val_tensor = x_tensor[val_idx]\n",
    "y_val_tensor = y_tensor[val_idx]\n",
    "\n",
    "# We're not doing any data augmentation now\n",
    "train_composer = Compose([Normalize(mean=(.5,), std=(.5,))])\n",
    "val_composer = Compose([Normalize(mean=(.5,), std=(.5,))])\n",
    "\n",
    "# Uses custom dataset to apply composed transforms to each set\n",
    "train_dataset = TransformedTensorDataset(x_train_tensor, y_train_tensor, transform=train_composer)\n",
    "val_dataset = TransformedTensorDataset(x_val_tensor, y_val_tensor, transform=val_composer)\n",
    "\n",
    "# Builds a weighted random sampler to handle imbalanced classes\n",
    "sampler = make_balanced_sampler(y_train_tensor)\n",
    "\n",
    "# Uses sampler in the training set to get a balanced data loader\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=16, sampler=sampler)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 4",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m x_train_tensor \u001b[38;5;241m=\u001b[39m x_tensor[train_idx]\n\u001b[0;32m     12\u001b[0m y_train_tensor \u001b[38;5;241m=\u001b[39m y_tensor[train_idx]\n\u001b[1;32m---> 13\u001b[0m x_val_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mx_tensor\u001b[49m\u001b[43m[\u001b[49m\u001b[43mval_idx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     14\u001b[0m y_val_tensor \u001b[38;5;241m=\u001b[39m y_tensor[val_idx]\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# We're not doing any data augmentation now\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for tensor of dimension 4"
     ]
    }
   ],
   "source": [
    "from helpers import index_splitter\n",
    "# Builds tensors from numpy arrays BEFORE split\n",
    "# Modifies the scale of pixel values from [0, 255] to [0, 1]\n",
    "x_tensor = torch.as_tensor(images / 255).float()\n",
    "y_tensor = torch.as_tensor(labels).long()\n",
    "\n",
    "# Uses index_splitter to generate indices for training and\n",
    "# validation sets\n",
    "train_idx, val_idx = index_splitter(len(x_tensor), [80, 20])\n",
    "# Uses indices to perform the split\n",
    "x_train_tensor = x_tensor[train_idx]\n",
    "y_train_tensor = y_tensor[train_idx]\n",
    "x_val_tensor = x_tensor[val_idx]\n",
    "y_val_tensor = y_tensor[val_idx]\n",
    "\n",
    "# We're not doing any data augmentation now\n",
    "train_composer = Compose([Normalize(mean=(.5,), std=(.5,))])\n",
    "val_composer = Compose([Normalize(mean=(.5,), std=(.5,))])\n",
    "\n",
    "# Uses custom dataset to apply composed transforms to each set\n",
    "train_dataset = TransformedTensorDataset(x_train_tensor, y_train_tensor, transform=train_composer)\n",
    "val_dataset = TransformedTensorDataset(x_val_tensor, y_val_tensor, transform=val_composer)\n",
    "\n",
    "# Builds a weighted random sampler to handle imbalanced classes\n",
    "sampler = make_balanced_sampler(y_train_tensor)\n",
    "\n",
    "# Uses sampler in the training set to get a balanced data loader\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=16, sampler=sampler)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1, 10, 10])\n",
      "torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "print(x_tensor.shape)  # Should be something like (N, C, H, W)\n",
    "print(y_tensor.shape)  # Should be something like (N,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "print(len(train_idx))  # Should be equal to number of samples in training set\n",
    "print(len(val_idx))    # Should be equal to number of samples in validation set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "print(len(train_idx))  # Should be equal to number of samples in training set\n",
    "print(len(val_idx))    # Should be equal to number of samples in validation set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_tensor shape: torch.Size([100, 1, 10, 10])\n",
      "y_tensor shape: torch.Size([100])\n",
      "train_idx length: 80\n",
      "val_idx length: 20\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 4",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 24\u001b[0m\n\u001b[0;32m     22\u001b[0m x_train_tensor \u001b[38;5;241m=\u001b[39m x_tensor[train_idx]\n\u001b[0;32m     23\u001b[0m y_train_tensor \u001b[38;5;241m=\u001b[39m y_tensor[train_idx]\n\u001b[1;32m---> 24\u001b[0m x_val_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mx_tensor\u001b[49m\u001b[43m[\u001b[49m\u001b[43mval_idx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     25\u001b[0m y_val_tensor \u001b[38;5;241m=\u001b[39m y_tensor[val_idx]\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Define normalization transforms for training and validation sets\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for tensor of dimension 4"
     ]
    }
   ],
   "source": [
    "from helpers import index_splitter, make_balanced_sampler\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import Compose, Normalize\n",
    "import torch\n",
    "\n",
    "# Convert numpy arrays to PyTorch tensors and normalize pixel values\n",
    "x_tensor = torch.as_tensor(images / 255.0).float()\n",
    "y_tensor = torch.as_tensor(labels).long()\n",
    "\n",
    "# Check tensor shapes\n",
    "print(f\"x_tensor shape: {x_tensor.shape}\")\n",
    "print(f\"y_tensor shape: {y_tensor.shape}\")\n",
    "\n",
    "# Split indices into training and validation sets\n",
    "train_idx, val_idx = index_splitter(len(x_tensor), [80, 20])\n",
    "\n",
    "# Ensure indices are valid\n",
    "print(f\"train_idx length: {len(train_idx)}\")\n",
    "print(f\"val_idx length: {len(val_idx)}\")\n",
    "\n",
    "# Apply the split to tensors\n",
    "x_train_tensor = x_tensor[train_idx]\n",
    "y_train_tensor = y_tensor[train_idx]\n",
    "x_val_tensor = x_tensor[val_idx]\n",
    "y_val_tensor = y_tensor[val_idx]\n",
    "\n",
    "# Define normalization transforms for training and validation sets\n",
    "transform = Compose([Normalize(mean=(0.5,), std=(0.5,))])\n",
    "\n",
    "# Create datasets with transformations applied\n",
    "train_dataset = TransformedTensorDataset(x_train_tensor, y_train_tensor, transform=transform)\n",
    "val_dataset = TransformedTensorDataset(x_val_tensor, y_val_tensor, transform=transform)\n",
    "\n",
    "# Create a weighted random sampler to handle class imbalance\n",
    "sampler = make_balanced_sampler(y_train_tensor)\n",
    "\n",
    "# Create data loaders for training and validation sets\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=16, sampler=sampler)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 2, 0, 1, 0, 0, 1, 1, 0, 2, 1, 0, 1, 1, 2, 0, 1, 2, 0, 2, 1, 1, 2, 2,\n",
       "        2, 1, 1, 1, 1, 2, 0, 2, 2, 1, 0, 2, 1, 0, 2, 0, 0, 2, 1, 0, 0, 1, 1, 2,\n",
       "        2, 0, 2, 2, 2, 2, 1, 2, 2, 0, 1, 2, 1, 2, 0, 1, 0, 0, 2, 1, 0, 1, 0, 0,\n",
       "        1, 2, 1, 0, 2, 1, 1, 0])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_val_tensor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mx_val_tensor\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x_val_tensor' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "x_val_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
