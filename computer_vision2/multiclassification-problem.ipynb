{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from image_classification import generate_dataset\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##data generation\n",
    "images , lables = generate_dataset(img_size= 10 , n_images= 1000, binary= False, seed= 17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "pic should not have > 4 channels. Got 10 channels.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtransforms\u001b[39;00m \n\u001b[0;32m      2\u001b[0m toimage \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mToPILImage()\n\u001b[1;32m----> 3\u001b[0m \u001b[43mtoimage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\software\\miniconda\\envs\\mlenv\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:234\u001b[0m, in \u001b[0;36mToPILImage.__call__\u001b[1;34m(self, pic)\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pic):\n\u001b[0;32m    226\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;124;03m        pic (Tensor or numpy.ndarray): Image to be converted to PIL Image.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    232\u001b[0m \n\u001b[0;32m    233\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_pil_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\software\\miniconda\\envs\\mlenv\\Lib\\site-packages\\torchvision\\transforms\\functional.py:286\u001b[0m, in \u001b[0;36mto_pil_image\u001b[1;34m(pic, mode)\u001b[0m\n\u001b[0;32m    284\u001b[0m     \u001b[38;5;66;03m# check number of channels\u001b[39;00m\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pic\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m4\u001b[39m:\n\u001b[1;32m--> 286\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpic should not have > 4 channels. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpic\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m channels.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    288\u001b[0m npimg \u001b[38;5;241m=\u001b[39m pic\n\u001b[0;32m    289\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pic, torch\u001b[38;5;241m.\u001b[39mTensor):\n",
      "\u001b[1;31mValueError\u001b[0m: pic should not have > 4 channels. Got 10 channels."
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as transforms \n",
    "toimage = transforms.ToPILImage()\n",
    "toimage(images[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 10, 10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_channel_image = images[0].squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = toimage(single_channel_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_channel_image = images[0][0, :, :]  # Extract the first channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib  \n",
    "def plot_images(image, lables, n_plot= 5):\n",
    "\n",
    "    n_plot = min(n_plot , len(images))\n",
    "\n",
    "    cols = 5 \n",
    "    rows = (n_plot + cols -1 ) // cols \n",
    "\n",
    "    #plt \n",
    "    fig, axes = plt.subplots(rows, cols, figsize= (15, rows*3))\n",
    "    axes = axes.flattern()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'flattern'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mplot_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mjpt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[30], line 12\u001b[0m, in \u001b[0;36mplot_images\u001b[1;34m(image, lables, n_plot)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m#plt \u001b[39;00m\n\u001b[0;32m     11\u001b[0m fig, axes \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(rows, cols, figsize\u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m15\u001b[39m, rows\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m3\u001b[39m))\n\u001b[1;32m---> 12\u001b[0m axes \u001b[38;5;241m=\u001b[39m \u001b[43maxes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflattern\u001b[49m()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'flattern'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x300 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_images(image= img , lables='jpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#index splitter \n",
    "from torch.utils.data import random_split\n",
    "def index_splitter(n, splits ,seed = 13):\n",
    "    idx = torch.arange(n)\n",
    "    splits_tensors=  torch.as_tensor(splits)\n",
    "    multiplier = n / splits_tensors.sum()\n",
    "    splits_tensors= (multiplier * splits_tensors).long() \n",
    "    diff = n - splits_tensors.sum()\n",
    "    splits_tensors[0] = splits[0] + diff\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "    return random_split(idx, splits_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "## data preparation\n",
    "class TransformedDataset(Dataset):\n",
    "    def __init__(self, X, Y, transform= None):\n",
    "        self.x = X\n",
    "        self.y = Y\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.transform:\n",
    "            X = self.x[index]\n",
    "        return X, self.y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data  import random_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import WeightedRandomSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import Compose\n",
    "\n",
    "#convert into tensor\n",
    "x_tensor= torch.as_tensor(images/255).float() \n",
    "y_tensor=torch.as_tensor(lables).long()\n",
    "\n",
    "#index splitter\n",
    "train_idx, val_idx = index_splitter(len(x_tensor) , [80,20])\n",
    "def index_splitter(n, splits, seed=13):\n",
    "    idx = torch.arange(n)\n",
    "\n",
    "    splits_tensor = torch.as_tensor(splits)\n",
    "   \n",
    "    multiplier = n / splits_tensor.sum()    \n",
    "    splits_tensor = (multiplier * splits_tensor).long()\n",
    "    \n",
    "    diff = n - splits_tensor.sum()\n",
    "    splits_tensor[0] += diff\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "    return random_split(idx, splits_tensor)\n",
    "\n",
    "#use indicies to perform splits\n",
    "x_train_tensor= x_tensor[train_idx]\n",
    "y_train_tensor= y_tensor[train_idx]\n",
    "x_val_tensor= x_tensor[val_idx]\n",
    "y_val_tensor=y_tensor[val_idx]\n",
    "\n",
    "\n",
    "train_compose= Compose( [transforms.Normalize(mean = (.5), std=(.5))])\n",
    "val_compose = Compose([transforms.Normalize(mean= (.5), std=(.5))])\n",
    "\n",
    "#use custom dataset to apply composed transfors to each set\n",
    "train_dataset = TransformedDataset(X = x_train_tensor, Y =  y_train_tensor, transform= train_compose)\n",
    "val_dataset = TransformedDataset(X = y_val_tensor, Y = y_val_tensor, transform= val_compose)\n",
    "\n",
    "#builds a weighted random sampler to handel imblanced classes \n",
    "\n",
    "def make_balanced_sampler(y):\n",
    "    # Computes weights for compensating imbalanced classes\n",
    "    classes, counts = y.unique(return_counts=True)\n",
    "    weights = 1.0 / counts.float()\n",
    "    sample_weights = weights[y.squeeze().long()]\n",
    "    # Builds sampler with compute weights\n",
    "    generator = torch.Generator()\n",
    "    sampler = WeightedRandomSampler(\n",
    "        weights=sample_weights,\n",
    "        num_samples=len(sample_weights),\n",
    "        generator=generator,\n",
    "        replacement=True\n",
    "    )\n",
    "    return sampler\n",
    "\n",
    "sampler= make_balanced_sampler(y_train_tensor)\n",
    "\n",
    "#uses sampelr in the training set to get a balanced data loader \n",
    "train_loader= DataLoader(dataset= train_dataset,\n",
    "                         batch_size= 16,\n",
    "                         sampler= sampler)\n",
    "    \n",
    "val_loader = DataLoader(dataset= val_dataset, \n",
    "                        batch_size= 16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_balanced_sampler(y):\n",
    "    # Computes weights for compensating imbalanced classes\n",
    "    classes, counts = y.unique(return_counts=True)\n",
    "    weights = 1.0 / counts.float()\n",
    "    sample_weights = weights[y.squeeze().long()]\n",
    "    # Builds sampler with compute weights\n",
    "    generator = torch.Generator()\n",
    "    sampler = WeightedRandomSampler(\n",
    "        weights=sample_weights,\n",
    "        num_samples=len(sample_weights),\n",
    "        generator=generator,\n",
    "        replacement=True\n",
    "    )\n",
    "    return sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([800])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0034, 0.0038, 0.0034, 0.0038, 0.0034, 0.0041, 0.0041, 0.0034, 0.0038,\n",
       "        0.0038, 0.0034, 0.0034, 0.0041, 0.0034, 0.0034, 0.0041, 0.0034, 0.0038,\n",
       "        0.0041, 0.0034, 0.0041, 0.0034, 0.0034, 0.0041, 0.0038, 0.0041, 0.0038,\n",
       "        0.0034, 0.0034, 0.0034, 0.0041, 0.0038, 0.0034, 0.0034, 0.0038, 0.0041,\n",
       "        0.0038, 0.0038, 0.0034, 0.0038, 0.0034, 0.0041, 0.0038, 0.0034, 0.0034,\n",
       "        0.0034, 0.0041, 0.0038, 0.0041, 0.0038, 0.0038, 0.0034, 0.0034, 0.0034,\n",
       "        0.0038, 0.0034, 0.0041, 0.0041, 0.0038, 0.0038, 0.0041, 0.0041, 0.0038,\n",
       "        0.0034, 0.0041, 0.0034, 0.0034, 0.0034, 0.0041, 0.0041, 0.0034, 0.0038,\n",
       "        0.0038, 0.0034, 0.0034, 0.0038, 0.0034, 0.0038, 0.0038, 0.0038, 0.0038,\n",
       "        0.0041, 0.0034, 0.0034, 0.0038, 0.0034, 0.0041, 0.0038, 0.0038, 0.0034,\n",
       "        0.0034, 0.0038, 0.0041, 0.0038, 0.0034, 0.0034, 0.0041, 0.0041, 0.0041,\n",
       "        0.0038, 0.0041, 0.0034, 0.0034, 0.0034, 0.0038, 0.0034, 0.0041, 0.0041,\n",
       "        0.0038, 0.0038, 0.0041, 0.0034, 0.0038, 0.0038, 0.0038, 0.0041, 0.0041,\n",
       "        0.0034, 0.0041, 0.0034, 0.0038, 0.0038, 0.0041, 0.0034, 0.0034, 0.0038,\n",
       "        0.0034, 0.0034, 0.0034, 0.0034, 0.0034, 0.0038, 0.0041, 0.0041, 0.0038,\n",
       "        0.0034, 0.0038, 0.0041, 0.0041, 0.0034, 0.0041, 0.0041, 0.0034, 0.0041,\n",
       "        0.0034, 0.0034, 0.0034, 0.0038, 0.0041, 0.0038, 0.0034, 0.0038, 0.0034,\n",
       "        0.0041, 0.0041, 0.0038, 0.0038, 0.0038, 0.0038, 0.0038, 0.0038, 0.0034,\n",
       "        0.0038, 0.0038, 0.0038, 0.0034, 0.0041, 0.0038, 0.0038, 0.0034, 0.0038,\n",
       "        0.0034, 0.0041, 0.0041, 0.0041, 0.0041, 0.0041, 0.0038, 0.0038, 0.0034,\n",
       "        0.0034, 0.0038, 0.0038, 0.0038, 0.0034, 0.0034, 0.0038, 0.0041, 0.0034,\n",
       "        0.0034, 0.0041, 0.0041, 0.0041, 0.0041, 0.0041, 0.0034, 0.0041, 0.0041,\n",
       "        0.0041, 0.0041, 0.0034, 0.0041, 0.0038, 0.0034, 0.0041, 0.0041, 0.0038,\n",
       "        0.0034, 0.0034, 0.0038, 0.0038, 0.0034, 0.0038, 0.0038, 0.0034, 0.0034,\n",
       "        0.0038, 0.0034, 0.0034, 0.0041, 0.0041, 0.0034, 0.0038, 0.0041, 0.0034,\n",
       "        0.0034, 0.0038, 0.0034, 0.0038, 0.0041, 0.0038, 0.0041, 0.0038, 0.0041,\n",
       "        0.0041, 0.0034, 0.0041, 0.0038, 0.0038, 0.0041, 0.0041, 0.0034, 0.0038,\n",
       "        0.0034, 0.0041, 0.0034, 0.0034, 0.0041, 0.0038, 0.0041, 0.0041, 0.0034,\n",
       "        0.0034, 0.0041, 0.0038, 0.0038, 0.0041, 0.0034, 0.0038, 0.0038, 0.0041,\n",
       "        0.0038, 0.0038, 0.0038, 0.0041, 0.0034, 0.0034, 0.0034, 0.0041, 0.0034,\n",
       "        0.0038, 0.0041, 0.0038, 0.0034, 0.0041, 0.0041, 0.0034, 0.0038, 0.0034,\n",
       "        0.0034, 0.0034, 0.0038, 0.0041, 0.0041, 0.0038, 0.0038, 0.0041, 0.0041,\n",
       "        0.0034, 0.0041, 0.0041, 0.0041, 0.0038, 0.0034, 0.0038, 0.0041, 0.0038,\n",
       "        0.0034, 0.0038, 0.0041, 0.0034, 0.0034, 0.0041, 0.0041, 0.0038, 0.0034,\n",
       "        0.0034, 0.0034, 0.0038, 0.0038, 0.0038, 0.0041, 0.0034, 0.0041, 0.0038,\n",
       "        0.0038, 0.0041, 0.0034, 0.0034, 0.0034, 0.0034, 0.0034, 0.0038, 0.0034,\n",
       "        0.0041, 0.0034, 0.0034, 0.0034, 0.0038, 0.0038, 0.0041, 0.0041, 0.0041,\n",
       "        0.0038, 0.0038, 0.0038, 0.0034, 0.0038, 0.0041, 0.0041, 0.0034, 0.0034,\n",
       "        0.0034, 0.0041, 0.0041, 0.0038, 0.0041, 0.0041, 0.0041, 0.0041, 0.0034,\n",
       "        0.0034, 0.0034, 0.0038, 0.0038, 0.0041, 0.0041, 0.0038, 0.0041, 0.0041,\n",
       "        0.0034, 0.0041, 0.0034, 0.0034, 0.0034, 0.0041, 0.0038, 0.0041, 0.0034,\n",
       "        0.0034, 0.0041, 0.0038, 0.0038, 0.0038, 0.0038, 0.0041, 0.0041, 0.0038,\n",
       "        0.0041, 0.0041, 0.0038, 0.0038, 0.0038, 0.0034, 0.0041, 0.0041, 0.0038,\n",
       "        0.0041, 0.0038, 0.0041, 0.0034, 0.0034, 0.0041, 0.0041, 0.0041, 0.0038,\n",
       "        0.0034, 0.0041, 0.0041, 0.0041, 0.0034, 0.0038, 0.0034, 0.0034, 0.0038,\n",
       "        0.0038, 0.0038, 0.0038, 0.0041, 0.0041, 0.0038, 0.0034, 0.0034, 0.0038,\n",
       "        0.0034, 0.0034, 0.0038, 0.0041, 0.0034, 0.0034, 0.0041, 0.0034, 0.0034,\n",
       "        0.0038, 0.0034, 0.0041, 0.0034, 0.0038, 0.0034, 0.0041, 0.0034, 0.0034,\n",
       "        0.0038, 0.0034, 0.0034, 0.0038, 0.0034, 0.0041, 0.0034, 0.0038, 0.0041,\n",
       "        0.0034, 0.0034, 0.0041, 0.0034, 0.0041, 0.0034, 0.0034, 0.0038, 0.0041,\n",
       "        0.0038, 0.0038, 0.0034, 0.0034, 0.0038, 0.0041, 0.0041, 0.0034, 0.0034,\n",
       "        0.0041, 0.0041, 0.0034, 0.0041, 0.0038, 0.0034, 0.0041, 0.0041, 0.0034,\n",
       "        0.0034, 0.0034, 0.0034, 0.0038, 0.0034, 0.0034, 0.0041, 0.0034, 0.0041,\n",
       "        0.0038, 0.0038, 0.0034, 0.0041, 0.0038, 0.0038, 0.0041, 0.0034, 0.0034,\n",
       "        0.0034, 0.0041, 0.0041, 0.0038, 0.0034, 0.0038, 0.0041, 0.0038, 0.0041,\n",
       "        0.0034, 0.0038, 0.0038, 0.0034, 0.0041, 0.0038, 0.0034, 0.0038, 0.0038,\n",
       "        0.0041, 0.0041, 0.0034, 0.0041, 0.0038, 0.0038, 0.0038, 0.0041, 0.0038,\n",
       "        0.0034, 0.0038, 0.0041, 0.0034, 0.0038, 0.0034, 0.0034, 0.0038, 0.0038,\n",
       "        0.0034, 0.0041, 0.0041, 0.0034, 0.0034, 0.0038, 0.0041, 0.0034, 0.0041,\n",
       "        0.0038, 0.0038, 0.0038, 0.0038, 0.0038, 0.0034, 0.0034, 0.0038, 0.0038,\n",
       "        0.0038, 0.0038, 0.0038, 0.0041, 0.0034, 0.0041, 0.0041, 0.0038, 0.0038,\n",
       "        0.0034, 0.0034, 0.0041, 0.0034, 0.0038, 0.0038, 0.0041, 0.0041, 0.0034,\n",
       "        0.0034, 0.0041, 0.0034, 0.0034, 0.0041, 0.0034, 0.0034, 0.0034, 0.0034,\n",
       "        0.0038, 0.0038, 0.0034, 0.0041, 0.0034, 0.0038, 0.0041, 0.0041, 0.0041,\n",
       "        0.0038, 0.0038, 0.0041, 0.0034, 0.0038, 0.0041, 0.0034, 0.0038, 0.0038,\n",
       "        0.0034, 0.0038, 0.0034, 0.0034, 0.0041, 0.0038, 0.0038, 0.0034, 0.0038,\n",
       "        0.0038, 0.0041, 0.0034, 0.0041, 0.0034, 0.0041, 0.0034, 0.0034, 0.0041,\n",
       "        0.0041, 0.0041, 0.0038, 0.0038, 0.0038, 0.0038, 0.0041, 0.0038, 0.0034,\n",
       "        0.0034, 0.0041, 0.0038, 0.0038, 0.0038, 0.0038, 0.0038, 0.0041, 0.0034,\n",
       "        0.0041, 0.0034, 0.0041, 0.0034, 0.0034, 0.0038, 0.0038, 0.0038, 0.0038,\n",
       "        0.0034, 0.0038, 0.0038, 0.0038, 0.0038, 0.0041, 0.0034, 0.0038, 0.0038,\n",
       "        0.0034, 0.0038, 0.0038, 0.0034, 0.0038, 0.0038, 0.0034, 0.0038, 0.0041,\n",
       "        0.0034, 0.0034, 0.0034, 0.0034, 0.0041, 0.0038, 0.0038, 0.0041, 0.0034,\n",
       "        0.0034, 0.0034, 0.0038, 0.0041, 0.0034, 0.0038, 0.0034, 0.0041, 0.0041,\n",
       "        0.0041, 0.0034, 0.0034, 0.0041, 0.0038, 0.0038, 0.0038, 0.0034, 0.0034,\n",
       "        0.0034, 0.0041, 0.0034, 0.0038, 0.0038, 0.0038, 0.0034, 0.0038, 0.0034,\n",
       "        0.0041, 0.0034, 0.0041, 0.0034, 0.0038, 0.0034, 0.0041, 0.0041, 0.0034,\n",
       "        0.0041, 0.0038, 0.0034, 0.0041, 0.0034, 0.0034, 0.0041, 0.0041, 0.0034,\n",
       "        0.0034, 0.0038, 0.0041, 0.0041, 0.0038, 0.0038, 0.0034, 0.0041, 0.0034,\n",
       "        0.0041, 0.0034, 0.0041, 0.0038, 0.0038, 0.0034, 0.0041, 0.0041, 0.0038,\n",
       "        0.0038, 0.0034, 0.0041, 0.0038, 0.0041, 0.0038, 0.0041, 0.0034, 0.0034,\n",
       "        0.0041, 0.0038, 0.0034, 0.0034, 0.0041, 0.0038, 0.0034, 0.0034, 0.0041,\n",
       "        0.0041, 0.0034, 0.0034, 0.0041, 0.0034, 0.0038, 0.0034, 0.0034, 0.0034,\n",
       "        0.0034, 0.0034, 0.0034, 0.0041, 0.0038, 0.0038, 0.0041, 0.0041, 0.0034,\n",
       "        0.0041, 0.0038, 0.0038, 0.0038, 0.0038, 0.0041, 0.0041, 0.0041, 0.0041,\n",
       "        0.0038, 0.0034, 0.0041, 0.0034, 0.0038, 0.0034, 0.0038, 0.0038, 0.0041,\n",
       "        0.0038, 0.0038, 0.0038, 0.0034, 0.0041, 0.0041, 0.0041, 0.0034, 0.0034,\n",
       "        0.0034, 0.0041, 0.0041, 0.0038, 0.0038, 0.0038, 0.0038, 0.0034, 0.0034,\n",
       "        0.0041, 0.0034, 0.0038, 0.0034, 0.0038, 0.0041, 0.0034, 0.0041])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w[y_train_tensor.long()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0038, 0.0034, 0.0041])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0038)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w[torch.tensor(0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
